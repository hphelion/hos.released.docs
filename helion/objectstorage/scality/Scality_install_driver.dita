<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="scality_install_driver">
  <title>Install the Scality Drivers</title>
  <body>
    
    <p>Scality RING storage can integrate with Helion's datacenter. Scality provides a block storage interface for OpenStack compute through the Cinder API and integration with OpenStack Swift as an alternative storage back end.</p>
    
    <p>To integrate Scality RING storage with Helion, you must install and configure the following drivers:</p>
<ol>
  <li><xref type="section" href="#scality_install_driver/swift_driver">Install the Scality Driver for Swift</xref></li>
  <li><xref type="section" href="#scality_install_driver/glance_driver">Install the Scality Driver for Glance</xref></li>
  <li><xref type="section" href="#scality_install_driver/cinder_driver">Install the Scality Driver for Cinder</xref></li>
    </ol>



<section id="swift_driver_overview">
  
  <title>Install the Scality Driver for Swift</title>
  
  <p>To install the Swift driver, you must complete the following tasks:</p>
  <ol>
    <li>Download and install the driver</li>
    <li>Update the configuration on the controller nodes</li>
    <li>Populate bootstrap entries on the RING storage node</li>
    <li>Commit changes and deploy.</li>
  </ol>
</section>
  
  <section id="swift_driver">
  <title>Download and Install the Driver</title>
  <p>To download the driver:</p>
  <ol>
    <li>To create a directory for the driver package, run:
    <codeblock>cd ~/scratch
    mkdir pkg</codeblock></li>
    <li>To download and extract the driver, run:
    <codeblock>cd ~/scratch/pkg
wget https://github.com/scality/ScalitySproxydSwift/archive/swift-scality-backend-0.4.0.tar.gz
tar xzf swift-scality-backend-0.4.0.tar.gz
 
wget  https://github.com/scality/scality-sproxyd-client/archive/scality-sproxyd-client-0.1.1.tar.gz
tar xzf scality-sproxyd-client-0.1.1.tar.gz
    </codeblock></li>
    <li>To install the 3rd-party driver</li>
  </ol>
</section>
    
    <section id="TinT_NFS">
      
      <title>Configure NFS</title>
      <p> Helion OpenStack uses Network File System (NFS) as the distributed file system protocol. NFS allows you to share a directory on a network. The computers or devices connecting to the shared directory usually mount the shared directory to make it a part of their own directory structure.</p>
      <p>To configure NFS to work with the TinTri driver, verify that NFS-common is installed on the controller, create and verify the volume mount, and edit the NFS settings.</p>
      <p>To configure NFS:</p>
<ol>
<li>To verify that NFS-common is installed on the controller, run:
          <codeblock>sudo dpkg -l | grep nfs</codeblock></li>
  <li>If NFS-common is not installed, to install it, run:
          <codeblock>sudo apt-get install nfs-common</codeblock></li>
  <li>To create and verify the volume mount, run the following commands:
          <codeblock>mkdir &lt;mountname&gt;
mkdir &lt;mountname&gt;/&lt;submountname&gt;
mount &lt;vmstore_data_ip&gt;:/tintri/&lt;submountname&gt;
            
For example:
mkdir m
mkdir m/cinder
mount 10.2.14.241:/tintri/cinder</codeblock></li>
  <li>To edit the NFS shares settings for TinTri, open the following file in a text editor:
          <codeblock>/etc/cinder/nfs_shares</codeblock></li>
  <li>To add the submount name, add the following text:
<codeblock>&lt;vmstore_data_ip&gt;:/tintri/&lt;submountname&gt;</codeblock>  
  </li>
</ol>   
    </section>
    
    <section id="TinT_backend">
    <title>Configuring TinTri as a Single-VMstore Backend</title>
      <p>To update your Cinder backend server to use TinTri storage, you must modify the appropriate Cinder configuration file. On the lifecycle manager, find the following file: <codeph>~/helion/my_cloud/config/cinder/cinder.conf.j2</codeph>. Add the following text:<codeph># Configure the enabled backends     Enabled_backends=tintri_vmstore</codeph></p>
       
    <p>To configure TinTri as a backend:</p>
    <ol>
      <li><xref type="section" href="#TinT_install_driver/TinT_Cinder">Add the TinTri backend to the Cinder configuration file.</xref></li>
      <li><xref type="section" href="#TinT_install_driver/TinT_Nova">Add NFS mount options to the Nova configuration file.</xref></li>
      <li><xref type="section" href="#TinT_install_driver/TinT_Commit">Commit your changes and reconfigure Cinder and Nova.</xref></li>
    </ol>
    </section>   
    
    <section id="TinT_Cinder">
      <title>Add the TinTri backend to the Cinder Configuration File</title>
      <p>To update your Cinder backend server to use TinTri storage, you must modify the Cinder configuration file on the lifecycle manager.</p>
      <p>To create a section for the TinTri backend:</p>
      <ol>
        <li>Log in to the lifecycle manager.</li>
          <li>Open the following file in a text editor:
          <codeblock>~/helion/my_cloud/config/Cinder.conf.j2</codeblock></li>
        <li>Add the following text:
            <codeblock>#configure the enabled backends
Enabled_backends=tintri_vmstore</codeblock><note
            type="important">If you are using multiple backend types, use a comma delimited list.
            For example, if you are using both TinTri and EMC backends, you can specifiy it as:
            <codeblock>Enabled_backends=tintri_vmstore,emc</codeblock></note></li>
        <li>To the <codeph>[tintri_vmstore]</codeph> section, add the following settings and fill in the values as per your cluster/environment:
            <table frame="all" rowsep="1" colsep="1" id="table_TinT_Cinder">
            <tgroup cols="2">
              <colspec colname="c1" colnum="1" colwidth="1.08*"/>
              <colspec colname="c2" colnum="2" colwidth="1*"/>
              <thead>
                <row>
                  <entry>Settings</entry>
                  <entry>Description</entry>
                </row>
              </thead>
              <tbody>
                <row>
                  <entry>volume_driver=cinder.volume.drivers.tintri.TintriDriver</entry>
                  <entry>Options defined in cinder.</entry>
                </row>
                <row>
                  <entry>nfs_mount_options=vers=3,lookupcache=pos</entry>
                  <entry>Mount options passed to the NFS client. For more details, refer to the NFS
                    man pages (string value)</entry>
                </row>
                <row>
                  <entry>tintri_server_hostname=&lt;Tintri VMstore Management IP&gt;</entry>
                  <entry>The hostname (or IP address) for the storage system. (string value)</entry>
                </row>
                <row>
                  <entry>tintri_server_username=&lt;username&gt;</entry>
                  <entry>User name for the storage system (string value)</entry>
                </row>
                <row>
                  <entry>tintri_server_password=&lt;password&gt;</entry>
                  <entry>Password for the storage system (string value)</entry>
                </row>
                <row>
                  <entry>nfs_shares_config=/etc/cinder/nfs_shares</entry>
                  <entry>This option is required for NFS configuration. It is the file with the list
                    of available NFS shares (string value)</entry>
                </row>
              </tbody>
            </tgroup>
          </table></li>
      </ol>
      <note type="note">The following is an example configuration:
        <codeblock>[tintri_vmstore]
volume_driver=cinder.volume.drivers.tintri.TintriDriver
volume_backend_name=NFS_tintri
nfs_mount_options=vers=3,lookupcache=pos
tintri_server_hostname=10.2.14.240
tintri_server_username=admin
tintri_server_password=tintriadmin
nfs_shares_config=/opt/stack/service/cinder-volume-20151019T060521Z/etc/nfs_shares</codeblock>
      </note>
    </section> 
    
    <section id="TinT_Nova">
      <title>Add NFS Mount Options to the NOVA Configuration File</title>
      <p>To add NFS mount options to the NOVA configuration file:</p>
      <ol>
        <li>Log in to the lifecycle manager.</li>
        <li>Find the following file:
          <codeblock>nova.conf.j2</codeblock> 
          For example:<codeph>~/helion/my_cloud/config/Nova/nova.conf.j2</codeph></li>
        <li>In a text editor, open the following file: <codeblock>nova.conf.j2</codeblock></li>
        <li>In the Nova configuration file, add the NSF changes to the <codeph>LIBVIRT</codeph>
          section. If this section does not exist, add it, and then add the following text:
          <codeblock># LIBVIRT
[libvirt]
virt_type = kvm
nfs_mount_options=vers=3,proto=tcp</codeblock></li>
      </ol>
    </section>
 
    <section id="TinT_Commit">
      <title>Commit Your Changes</title>
      <p>Commit your changes and reconfigure Cinder and Nova to finish integrating TinTri with Helion OpenStack.</p>
      <p>To finish configuring TinTri as a backend:</p>
      <ol>
        <li>To commit your configuration changes to a local git repository, run:
          <codeblock>cd ~/helion/hos/ansible
git add -A
git commit -m "&lt;your commit message&gt;"</codeblock></li>
        <li>To use an ansible playbook to run the configuration processor, run:
          <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml</codeblock></li>
        <li>To use an ansible playbook to create a deployment directory, run:
          <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost ready-deployment.yml</codeblock></li>
        <li>To use an ansible playbook to reconfigure Cinder, run:
          <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/verb_hosts cinder-reconfigure.yml</codeblock></li>
        <li>To use an ansible playbook to reconfigure Nova, run:
          <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/verb_hosts nova-reconfigure.yml</codeblock></li>
      </ol>
    </section>  
  
  </body>
</topic>
