<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="keystone_benchmarking">
  <title><ph conkeyref="HOS-conrefs/product-title"/>Keystone Identity Performance
    Benchmarking</title>
  <body>
    <p conkeyref="HOS-conrefs/applies-to"/>


    <section id="overview"><title>Overview</title> The purpose of this performance benchmark is to
      provide a reference for HPE Helion OpenStack Keystone users to know how the system performs
      under a particular environment and workload. There are several major operations where
      performance is critical: token creation, token validation, and user lookup when an LDAP back
      end is applied. <p>Other operations are available but performed less frequently. Thus we focus
        here on the benchmark tests and documentation for only these three major operations.</p>. </section>
    <section id="testEnv"><title>Performance test environment</title>
      <b>Server models and specifications</b></section>
    <section> Ideally, a performance test environment would be an exact replica of the production
      system but it’s not always possible. For this performance test, HP KS-PERF, as described in
      Table 1, was performed against a 7-node, HP DL360 Gen9-based servers in 'baremetal' mode. </section>
    
    <table frame="all" rowsep="1" colsep="1" id="specs">
      <tgroup cols="6">
        <colspec colname="c1" colnum="1" colwidth="2.32*"/>
        <colspec colname="c2" colnum="2" colwidth="1*"/>
        <colspec colname="c3" colnum="3" colwidth="2.74*"/>
        <colspec colname="c4" colnum="4" colwidth="5.51*"/>
        <colspec colnum="5" colname="c5" colwidth="3.7*"/>
        <colspec colnum="6" colname="c6" colwidth="3.63*"/>
        <thead>
          <row>
            <entry>Server</entry>
            <entry>Nodes</entry>
            <entry>Model</entry>
            <entry>Specifications</entry>
            <entry>Operating System</entry>
            <entry>Software Versions</entry>
          </row>
        </thead>
        <tbody>
          <row>
            <entry>
              <p>KS-Perf Servers</p>
            </entry>
            <entry>7</entry>
            <entry>
              <p>HP ProLiant DL360 Gen9)</p>
            </entry>
            <entry>
              <ul id="ol_mfn_xcm_25">
                <li>2 x Intel(R) Xeon(R) CPU E5-2650L v3 @ 1.80GHz</li>
                <li>132Gb RAM, dual 10Gb NIC in bonding mode</li>
              </ul>
            </entry>
            <entry>
              <p>hLinux cattleprod (3.14.44-1 kernel)</p>
            </entry>
            <entry>
              <ul>
                <li>HPE Helion OpenStack2.0</li>
                <li>HPE Helion OpenStack 1.1.1</li>
                <li>MySQL v5.5.41</li>
              </ul>
            </entry>
          </row>
          <row>
            <entry>
              <p>OpenLDAP Server</p>
            </entry>
            <entry>1</entry>
            <entry>
              <p>HP SE2170s Gen7</p>
            </entry>
            <entry>
              <ul id="ol_scv_2dm_25">
                <li>2 x Intel(R) Xeon(R) CPU X5650 @ 2.67GHz</li>
                <li>192Gb RAM, single 1Gb NIC</li>
              </ul>
            </entry>
            <entry>
              <p>Ubuntu 14.04.02 LTS (Trusty)</p>
            </entry>
            <entry>
              <p>OpenLDAP v2.4.31</p>
            </entry>
          </row>
        </tbody>
      </tgroup>
    </table>
    <section>Table 1 Server specifications for performance test </section>
    <section id="Keystone-LDAP"><title>Keystone-LDAP</title>
      <p>For the test cases with a domain-specific LDAP back end, and an OpenLDAP server employed,
        as described in Table 1, there are four LDAP domains (i.e. openldap50, openldap5k,
        openldap50k and openldap500k) with different numbers of users (i.e. 50, 5,000, 50,000 and
        500,000) respectively, as depicted in Figure 1 and Table 2. </p>
      <image href="../../media/keystone/HOSKeystoneDomain-SpecificBackend.png" id="image_eht_kcm_25"/>
      <p>Figure 1 LDAP users and groups for Keystone domains</p>
      <table frame="all" rowsep="1" colsep="1">
        <tgroup cols="5">
          <thead>
            <row>
          <entry>LDAP</entry>
          <entry>openldap50</entry>
          <entry>openldap5k</entry>
          <entry>openldap50k</entry>
          <entry>openldap500k</entry>
            </row>
        </thead>
          <tbody>
        <row>
          <entry>
            <p>User Container</p>
          </entry>
          <entry>
            <p>ou=Users50,dc=cdl,dc=hp,dc=com</p>
            <ul id="ul_orh_b2m_25">
              <li>user50_000001 to user50_000050</li>
            </ul>
          </entry>
          <entry>
            <p>ou=Users5k,dc=cdl,dc=hp,dc=com</p>
            <ul id="ul_urv_b2m_25">
              <li>user5k_000001 to user50_005000</li>
            </ul>
          </entry>
          <entry>
            <p>ou=Users50k,dc=cdl,dc=hp,dc=com</p>
            <ul id="ul_nj3_c2m_25">
              <li>user50k_000001 to user50k_050000</li>
            </ul>
          </entry>
          <entry>
            <p>ou=Users500k,dc=cdl,dc=hp,dc=com</p>
            <ul id="ul_nr5_c2m_25">
              <li>user500k_000001 to user500k_500000</li>
            </ul>
          </entry>
        </row>
        <row>
          <entry>
            <p>Group Container</p>
          </entry>
          <entry>
            <p>ou=Groups50,dc=cdl,dc=hp,dc=com</p>
            <ul id="ul_kl5_d2m_25">
              <li>
                <p> members of group50_1: </p>
                <p>user50_000001 to user50_000050 under Users50</p>
              </li>
            </ul>
          </entry>
          <entry>
            <p>ou=Groups5k,dc=cdl,dc=hp,dc=com</p>
            <ul id="ul_eff_22m_25">
              <li>
                <p> members of group5k_1: </p>
                <p>user5k_000001 to user5k_000050 under Users5k</p>
              </li>
            </ul>
          </entry>
          <entry>
            <p>ou=Groups50k,dc=cdl,dc=hp,dc=com</p>
            <ul id="ul_efq_22m_25">
              <li>
                <p>members of group50k_1: </p>
                <p>user50k_000001 to user50k_000050 under Users50k</p>
              </li>
            </ul>
          </entry>
          <entry>
            <p>ou=Groups500k,dc=cdl,dc=hp,dc=com</p>
            <ul id="ul_p52_f2m_25">
              <li>
                <p>members of group500k_1: </p>
                <p>user500k_000001 to user500k_000050 under Users500k</p>
              </li>
            </ul>
          </entry>
        </row>
          </tbody>
        </tgroup>
      </table><p>Table 2 LDAP user and group data structure for four Keystone domains (i.e.
        openldap50, openldap5k, openldap50k and openldap500k) </p></section>

    <section id="cache_mech"><title>Cache mechanism</title> Keystone supports a caching layer that
      is above the configurable subsystems (e.g. token, identity, etc). HPE Helion OpenStack
      Keystone uses the dogpile.cache library, allowing for flexible cache back ends. The majority
      of the caching configuration options are set in the [cache] section. However, each section
      that has the ability to be cached usually has a caching boolean value that will toggle caching
      for that specific section. For the performance test cases with caching turned on, the
      subsystem and the global toggle setting are enabled and dogpile.cache.memory is employed for
      this study as configured below. Please be advised that dogpile.cache.memory is an experimental
      cache provider and is not ready for production-level applications. <ol>
        <li>To begin, edit <codeph>etc/keystone.conf</codeph> with the [cache] section shown below
          <codeblock>[cache]
# enable caching across all of keystone
enabled = true
  
# use in-memory cache
backend = dogpile.cache.memory</codeblock>
        </li>
        <li>Verify that subsystem caching is enabled
          <codeblock>[catalog]
caching = true
  
[domain_config]
caching = true
  
[identity]
caching = true
  
[resource]
caching = true
  
[revoke]
caching = true
  
[role]
caching = true
  
[token]
caching = true</codeblock>
        </li>
        <li>Restart Apache2 for the update to take effect.</li>
      </ol> Additional Note: Concurrent test cases with the label 1K2P17U represent test conditions
      with one Keystone node, two processes configured in Apache2 and 17 concurrent users.
      Similarly, 3K2P50U has three Keystone nodes, two processes configured in Apache2 and 50
      concurrent users. <ul>
        <li>K represents number of Keystone nodes</li>
        <li>P represents number of processes configured in Apache2 sever</li>
        <li>U represents number of concurrent users</li>
      </ul>
    </section>
    <section id="domain_spec_back_end"><title>HPE Helion OpenStack 2.0 with domain-specific LDAP
        back end</title>
      <p><b>LDAP user lookup performance - HPE Helion OpenStack 2.0 Keystone user lookup performance
        </b></p> Figures 2.a through 2.c represent the performance of non-concurrent LDAP user
      lookup by name for HPE Helion OpenStack. The study of Keystone-LDAP query efficiency skips the
      authorization process by using an admin token. A baseline test using a direct LDAP client
      (i.e. ldapserach) was also performed for comparison. <ul>
        <li>Generally, having more LDAP users per domain results in a longer query response time for
          a domain user lookup.</li>
        <li>The response times grow roughly linearly with the number of domain users in LDAP, as
          shown in Figures 2.b and Figure 2.c. The response time slope for HPE Helion OpenStack 2.0
          is much flatter than for HPE Helion OpenStack 1.1.1.</li>
        <li>HPE Helion OpenStack 2.0 behaves between 10 and several thousand times better than HPE
          Helion OpenStack 1.1.1 for LDAP user lookup operations, especially for large numbers of
          LDAP users (e.g. 500,000 users) cases.</li>
      </ul>
      <image placement="break" href="../../media/keystone/Non-ConcurrentLDAPUserLookup_bars.png"
        id="image_rs1_5fv_q5" align="" outputclass=""/>
      <p>Figure 2.a Non-Concurrent LDAP User lookup by name</p><image placement="break"
        href="../../media/keystone/Non-ConcurrentLdapUserLookup_lines.png" id="image_srj_zfv_q5"/>
      <p>Figure 2.b Non-Concurrent LDAP User lookup by name</p>
      <image placement="break"
        href="../../media/keystone/Non-ConcurrentLdapUserLookup_base_lines.png"
        id="image_v5f_kjh_r5"/>
      <p>Figure 2.c Non-concurrent LDAP user lookup by name </p></section>

<section>
      <p><b>LDAP user lookup performance - concurrency impact on HPE Helion OpenStack 2.0
          Keystone</b></p> Figures 3.a and 3.b represent HPE Helion OpenStack 2.0 LDAP user lookup
      under concurrent conditions. <ul>
        <li>The response times grow roughly linearly with the number of domain users in LDAP even
          under concurrent conditions, as shown in Figure 3.b, but response time slopes vary for
          different race conditions. </li>
        <li>Compared with baseline non-concurrent LDAP user lookup for a specific number of LDAP
          users, the response time increases for cases with concurrent conditions by a factor of 5
          to 10. When increasing the number of concurrent users from 17 to 50 and Keystone nodes
          from 1 to 3 with the same average load per Keystone node (e.g. 50/3 ~ 17), the response
          time grows much higher by another factor of 2 to 3 for the case of 500,000 LDAP users.
          This shows that race conditions had  large impact on server efficiency (e.g. Keystone,
          Apache2, Keystone, and LDAP) leading to poorer responsiveness. </li>
      </ul>
      <image placement="break" href="../../media/keystone/HOS2_LdapUserLookup_bars.png"
        id="image_mrq_xtb_r5"/>
      <p>Figure 3.a LDAP User lookup by name for HPE Helion OpenStack 2.0 under concurrent
        conditions</p>
      <image href="../../media/keystone/HOS2_LdapUserLookup_lines.png" id="image_ggk_15b_r5"/>
      <p>Figure 3.b LDAP User lookup by name for HPE Helion OpenStack 2.0 under concurrent
        conditions</p>
    </section>
    <section><title>Creating project-scoped tokens</title>
      <p><b>Keystone performance on project-scoped token creation</b></p> Figures 4.a and 4.b
      represent performance on project-scoped token creation for a single Keystone node under
      non-concurrent conditions. <ul>
        <li>The response times for project-scoped token creation grow roughly linearly with the
          number of domain users in LDAP, as shown in Figure 4.b, but response time slopes vary for
          HPE Helion OpenStack versions and cached conditions. </li>
        <li>For non-cached cases of project-scoped token creation, HPE Helion OpenStack 2.0 performs
          slightly better than HPE Helion OpenStack1.1.1, that is within 5%. </li>
        <li>With the cache mechanism activated for the single Keystone node, the system shows
          obvious improvement in responsiveness for all cases of project-scoped token creation,
          especially for HPE Helion OpenStack 2.0 (see further detail in Figure 6.b). </li>
      </ul>
      <image href="../../media/keystone/CPST_Nonconcurrent_barrs.png" id="image_bzm_c3v_q5"
        placement="break"/>
      <p>Figure 4.a Performance on project-scoped token creation for a single Keystone node without
        concurrency</p>
      <image href="../../media/keystone/CPST_Nonconcurrent_lines.png" id="image_irn_f3v_q5"
        placement="break"/>
      <p>Figure 4.b Performance on project-scoped token creation for a single Keystone node without
        concurrency</p>
      <p>Figures 5.a and 5.b below represent performance on project-scoped token creation under
        concurrent conditions.</p>
      <ul>
        <li>The response times for a single Keystone node with concurrency grow roughly linearly
          with the number of domain users in LDAP, as shown in Figure 5.b, but response time slopes
          vary for HPE Helion OpenStack versions and and cached conditions. </li>
        <li>For non-cached cases of project-scoped token creation, HPE Helion OpenStack 2.0 performs
          slightly better than HPE Helion OpenStack1.1.1&#151;within 5%. </li>
        <li>With the cache mechanism activated for the single Keystone node, the system observes
          obvious responsiveness gains for all cases of project-scoped token creation. The
          improvement by cache for HPE Helion OpenStack 2.0 is even larger than for HPE Helion
          OpenStack 1.1.1 (see further detail in Figure 6.b and percentage Figure 6.a and 6.b).
        </li>
      </ul>
      <image placement="break" href="../../media/keystone/CPST_Concurrent_bars.png"
        id="image_gtl_53v_q5"/>
      <p>Figure 5.a Performance on project-scoped token creation with concurrency (1K2P17U)
        </p><image placement="break" href="../../media/keystone/CPST_Concurrent_lines.png"
        id="image_kkc_z3v_q5"/>
      <p>Figure 5.b Performance on project-scoped token creation with concurrency (1K2P17U)
          </p><p><b>Keystone improvements using caching</b></p>
      <p>The following figures represent performance improvement percentages on project-scoped token
        creation for a single Keystone node with non-concurrent conditions and a 17 concurrent user
        condition.</p><ul>
        <li>With the cache mechanism activated for the single Keystone node, the system observes
          obvious responsiveness gains for all cases of project-scoped token creation. </li>
        <li>The improvement for non-concurrent HPE Helion OpenStack 2.0 project-scoped token
          creation for a single Keystone node is about 45% and concurrent HPE Helion OpenStack 2.0
          about 40%. The improvement percentages stay stable for cases of different numbers of LDAP
          users. </li>
        <li>The improvement for non-concurrent HPE Helion OpenStack 1.1.1 project-scoped token
          creation for a single Keystone node is about 15%- 30% and for concurrent HPE Helion
          OpenStack 1.1.1 it is approximately 20%-28%. The improvement decreases with larger numbers
          of LDAP users. </li>
      </ul>
      <image placement="break" href="../../media/keystone/CPST_ImprovementByCache_bars.png"
        id="image_mtp_ppb_r5"/>
      <p>Figure 6.a Creating project-scoped token performance improvement percentage by cache.
        (Concurrency cases based on 1K2P17U)</p>
      <image placement="break" href="../../media/keystone/CPST_ImprovementByCache_lines.png"
        id="image_qf2_spb_r5"/>
      <p>Figure 6.b Creating project-scoped token performance improvement percentage by cache.
        (Concurrency cases based on 1K2P17U)</p>
      <p><b>Concurrency impact on HPE Helion OpenStack 2.0 Keystone</b></p>
      <p>The following figures represent the impact of concurrency on HPE Helion OpenStack 2.0
        performance for project-scoped token creation.</p>
      <ul>
        <li>The response times grow roughly linearly with the number of domain users in LDAP for all
          test cases here, as shown in Figure 7.b, but response time slopes vary for different race
          and cache conditions. </li>
        <li>Compared with the baseline non-cached non-concurrent project-scoped token creation for a
          specific number of LDAP users, the response time is greatly increasing for cases with
          concurrent conditions (by factor of 10). When increasing the number of concurrent users
          from 17 to 50 and Keystone nodes from 1 to 3 with about the same average load (i.e. 50/3 ~
          17) per Keystone node, the response times are not obvously different for a specific number
          of LDAP users under 50,000. However, the response times for 500,000 LDAP users grows by a
          factor of 2 to 3. The race conditions had a large impact on server efficiency (e.g.
          Apache2, Keystone, and LDAP) with 500,000 LDAP users. </li>
        <li>When turning on the cache mechanism within Keystone nodes, there are noticible
          improvements in responsiveness for all cases of project-scoped token creation. </li>
        <li>The improvement by cache for HPE Helion OpenStack 2.0 project-scoped token creation with
          either 17 or 50 non-concurrent users is about 40%. The improvement percentages stay stable
          for different numbers of LDAP users. </li>
      </ul>
      <image placement="break" href="../../media/keystone/HOS2_CPST_KPU_bars.png"
        id="image_hcd_qqb_r5"/> Figure 7.a Concurrency impact on Keystone under cached and
      non-cached conditions <image placement="break"
        href="../../media/keystone/HOS2_CPST_KPU_lines.png" id="image_wk4_wqb_r5"/>
      <p>Figure 7.b Concurrency impact on Keystone under cached and non-cached conditions</p>
    </section>
    <section><title>Summary</title> Below is a summary of the performance improvements for LDAP user
      lookups and  project-scoped token creation. <p><b>LDAP user lookup</b></p>
      <ul>
        <li>Generally, larger numbers of LDAP users for a domain results in greater query response
          times for a domain user lookup in a linear relationship with varied slopes, regardless of
          whether concurrency or non-concurrency is involved. </li>
        <li>HPE Helion OpenStack 2.0 behaves between 10 and several thousand times better than HPE
          Helion OpenStack 1.1.1 for LDAP user lookup operations, The greatest improvements are most
          noticeable for large user deployments. For example, the 500,000-user tests yielded a
          performance increase of several thousand lookup operations over the same period.</li>
        <li>The response time grows by factor of 5-10 for cases with concurrent conditions when
          compared with baseline non-concurrent LDAP user lookup for a specific number of LDAP
          users. When increasing the numbers of concurrent users from 17 to 50 and Keystone nodes
          from 1 to 3 with the same average load per Keystone node (e.g. 50/3 ~ 17), the response
          time grows much higher by another factor of 2 to 3 for the case of 500,000 LDAP users.
          This shows that race conditions had a large impact on server efficiency (e.g. Keystone,
          Apache2, Keystone, and LDAP) leading to poor responsiveness. </li>
      </ul>
      <p><b>Creating project-scoped tokens</b></p>
      <ul>
        <li>The response times for project-scoped token creation grow roughly linearly with the
          number of domain users in LDAP, but response time slopes vary for HPE Helion OpenStack
          versions and cached conditions, regardless of whether concurrency or non-concurrency is
          involved. </li>
        <li>HPE Helion OpenStack 2.0 performs slightly better than HPE Helion OpenStack1.1.1, within
          5% for project-scoped token creation. </li>
        <li>With the cache mechanism activated for the single Keystone node without concurrency,
          there were obvious responsiveness improvements for project-scoped token creation. <ul>
            <li>The improvement for non-concurrent HPE Helion OpenStack 2.0 project-scoped token
              creation for a single Keystone node is about 45% and for concurrent conditions it is
              approximately 40%. The improvement percentages stay stable with different numbers of
              LDAP users. </li>
            <li>The improvement for non-concurrent HPE Helion OpenStack 1.1.1 project-scoped token
              creation for a single Keystone node is about 15%- 30% and for concurrent conditions is
              about 20%-28%. The improvement decreases with larger numbers of LDAP users. </li>
          </ul></li>
        <li>With the cache mechanism activated for the single Keystone node with concurrency, the
          system shows obvious responsiveness improvements for project-scoped token creation. <ul>
            <li>The improvement by cache for HPE Helion OpenStack 2.0 project-scoped token creation
              with either 17 or 50 concurrent users is about 40%. The improvement percentages stay
              stable for different numbers of LDAP users. </li>
          </ul></li>
        <li>Compared with the baseline non-cached non-concurrent project-scoped token creation for a
          specific number of LDAP users, the response times are much higher under concurrent
          conditions (by factor of 10). When the number of concurrent users is increased from 17 to
          50 and the number of Keystone nodes is increased from 1 to 3 with about the same average
          load (i.e. 50/3 ~ 17) per Keystone node, the response times do not differ significantly
          for a specific number of LDAP users under 50,000. However, the response times for 500,000
          LDAP users grows by a factor of 2 to 3 as race conditions impact server efficiency (e.g.
          Apache2, Keystone, and LDAP) with 500,000 LDAP users. </li>
      </ul>
    </section>
  </body>
</topic>
