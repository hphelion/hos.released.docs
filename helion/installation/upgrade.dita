<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="upgradeto21">
  <title><keyword keyref="kw-hos"/> Upgrade from 2.0 to 2.1</title>
  <body>
    <!--<p conkeyref="HOS-conrefs/applies-to"/>-->

    <section><title>STILL MISING - HOW TO TELL IF THE NODES ARE BACK UP/STATUS ? HOW TO TELL WHICH
        NODES ARE WHICH? Correct file names...</title></section>
    <section id="about">
      <title>Performing the Upgrade from HPE Helion OpenStack 2.0 to 2.1</title>
      <p>HPE Helion OpenStack 2.0 shipped with example configuration files, and you were able to
        modify them to suit your needs.</p>
      <note type="caution">The configuration you specified will remain unchanged through the upgrade
        process; <b>however</b>, if you made any configuration changes by passing parameters to any
        Ansible playbooks using the -e option, you should find the affected files and make the
        required changes directly in the files in <b>helion/my_cloud</b> and commit them to the git
        repository so that those changes are tracked and applied during the upgrade process.
        Otherwise they will not be applied.</note>
      <p>You may also install HPE Helion OpenStack 2.1 as a full install. Those instructions are
        found in the installation guide.</p>
    </section>
    <section id="prereqs"><title>Prerequisites</title>
      <p>These steps assume you have an installed and working HPE Helion OpenStack 2.0 cloud.</p>
    </section>
    <section id="mainSteps"><title>Upgrade Overview</title> To perform the upgrade, the workflow
      will look something like this: <ol>
        <li>Run the upgrade deployer, which will apply updates to all nodes</li>
        <li>Determine which nodes are which</li>
        <li>Note the recommended order in which you should reboot nodes for Linux for HPE Helion
          changes to take effect</li>
        <li>Stop running services on the node you are about to reboot</li>
        <li>Reboot the node</li>
        <li>Wait until you can SSH to it before proceeding</li>
        <li>Repeat the process with the next node</li>
        <li>Note one additional step (step 7) that is specific to ESX deployments <b>during the
            upgrade run</b>, and one additional process for ESX deployments after all nodes are
          rebooted.</li>
        <li>Note changes specific to anyone running Helion Development Platform. These services:
          DNSaaS, ALS, DBaaS, CE, Messaging, may or may not need special stopping and
          restarting.</li>
      </ol></section>


    <section id="upgradesteps"><title>Upgrade Instructions</title>
      <ol>
        <li>To begin the upgrade process, log in to the lifecycle manager as the user you created
          during the HPE Helion OpenStack 2.0 deployment, and mount the install media at
            <codeph>/media/cdrom</codeph>; for example:
          <codeblock>sudo mount hLinux-cattleprod-amd64-blaster-netinst-20151009-hlm.2015-11-13T07:32:19_caf1ffc.iso /media/cdrom</codeblock></li>
        <li>Unpack the following
          tarball:<codeblock>tar faxv /media/cdrom/hos/hos-2.0.1-20151113T062512Z.tar</codeblock></li>
        <li>Run the included initialization script to update the deployer:
          <codeblock>~/hos-2.0.1/hos-init.bash</codeblock></li>
        <li>If you have made any made any changes to your configuration files, ensure that you
          commit them to your local git:
          <codeblock>cd ~/helion
git add –A
git commit –m "My changes"</codeblock></li>
        <li>Run the configuration processor:
          <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml</codeblock></li>
        <li>Run the ready deployment playbook:
          <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost ready-deployment.yml</codeblock></li>
        <li><b>ESX - additional step</b>: If you are using the Entry-scale with ESX model you will
          need to uncomment the EON upgrade step from the YAML file below: <codeblock>cd  ~/scratch/ansible/next/hos/ansible/_hlm-service-upgrade.yml</codeblock>
          <p>The line to uncomment is:</p>
          <codeblock>eon-upgrade.yml</codeblock></li>
        <li>Run the upgrade playbook (required for all models/deployments):
          <codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts hlm-upgrade.yml</codeblock></li>
        <li><b>ESX - additional step:</b> Once the upgrade is complete, skip to the <xref
            href="upgrade.dita#upgradeto21/esx">Further ESX Model Upgrade Instructions</xref>
          section.</li>
      </ol>
    </section>
    <section id="rebooting_general"><title>Rebooting Your Nodes</title>To complete the upgrade and
      for Linux for HPE Helion updates to take effect, you must reboot all your nodes. The
      instructions for rebooting controller, compute, and storage nodes are found below. Note that
      you should follow the order prescribed for each type of deployment, for example, Swift, VSA,
      or Ceph. Expand the sections below for those instructions.</section>
    <section id="expandCollapse">
      <sectiondiv outputclass="expandall">Expand All</sectiondiv>
      <sectiondiv outputclass="collapseall">Collapse All</sectiondiv>
    </section> 
    <section>
      <title outputclass="headerH">Recommended Node Reboot Order (General) </title>
      <sectiondiv outputclass="insideSection"><p>To ensure that rebooted nodes reintegrate into the
          cluster, you may want to reboot a control plane node, then a storage or compute node or
          two, then the next control plane node, then the remaining compute and storage nodes, then
          the last control plane node. This final control plane node can be the one that runs the
          deployer, if your deployer is in the control plane. </p>
        <p>Another option is to reboot the control plane first, and not reboot compute hosts until
          later, after migrating the VMs.</p></sectiondiv></section>

    <section id="vsa"><title outputclass="headerH">Node Reboot Order for VSA
        Deployments</title><sectiondiv outputclass="insideSection"> If your cloud is deployed with
        VSA, then the reboot sequence will be as follows: <ol>
          <li>controller node</li>
          <li>compute node</li>
          <li>VSA node</li>
        </ol> During reboot, volumes carved from the VSA cluster will not be accessible if the
        volums are using RAID 0. For non-RAID 0 volumes (such as RAID 1 or RAID 5, etc.), the volume
        will keep functioning in degraded mode and there will I/O will not be impacted. Also, it is
        recommended that you reboot VSA nodes in sequence for a given VSA cluster. <p>The sequence
          is as follows:</p> 
        <ol>
          <li>Identify all VSA node of a given cluster </li>
          <li>Reboot VSA node </li>
          <li>Check VSA service status </li>
          <li>Check cluster status using CMC </li>
          <li>Repeat step 2-4 for remaining node of VSA cluster. </li>
          <li>Go to step (1) and repeat all steps for other clusters</li>
        </ol>
      </sectiondiv>
    </section>

    <section id="reboot_ceph"><title outputclass="headerH">Node Reboot Order for Ceph
        Deployments</title>
      <sectiondiv outputclass="insideSection"> Note that Ceph has two components: <ul>
          <li>monitor nodes</li>
          <li>OSD nodes</li>
        </ul> Monitor nodes can be deployed on a controller node. In this case, the reboot sequence
        will be: <ol>
          <li>Controller node (reboot of this will take care of the monitor as well) </li>
          <li>Compute node </li>
          <li>Ceph OSD nodes </li>
        </ol>More commonly, the monitor is deployed as a standalone; i.e., as separate set of
        resource nodes. In this case the reboot sequence will be: <ol>
          <li>Controller node </li>
          <li>Compute node </li>
          <li>Ceph monitor node </li>
          <li>Ceph OSD nodes </li>
        </ol> In both cases, please ensure that you are serializing the reboot of a given family
        (monitor or OSD or controller); that is, don't reboot them all at the same time. This will
        ensure that each service is up and running and there is no impact on the client side. To
        reboot Ceph nodes, follow the sequence below to safely reboot the entire Ceph cluster: <ol>
          <li>Reboot a Ceph monitor node in the cluster. </li>
          <li>Once the monitor node comes up, wait for a minute and then execute the following
            command:
            <codeblock>ansible-playbook -i hosts/verb_hosts ceph-status.yml --limit &lt;monitor-hostname></codeblock>
          </li>
          <li>If the above playbook executes successfully, repeat from step 1 to reboot the next
            Ceph monitor node in the cluster. </li>
          <li>Once all the monitor nodes have been rebooted, execute "
            <codeblock>ceph quorum_status </codeblock>on a monitor node and ensure that all the
            monitors have joined the quorum by observing that in the output, the "quorum_names"
            section lists all the monitors in the Ceph cluster. </li>
          <li>Now reboot an OSD node in the cluster. </li>
          <li>Once the OSD node comes up, wait for 5 minutes and then execute the following command:
            <codeblock>ansible-playbook -i hosts/verb_hosts ceph-status.yml --limit &lt;OSD-hostname></codeblock>
          </li>
          <li>If the above playbook executes successfully, repeat from step 5 for another Ceph OSD
            node in the cluster. </li>
          <li>Once the entire cluster is rebooted, execute command
            <codeblock>ceph health detail </codeblock>to ensure that you see HEALTH_OK. </li>
        </ol>
      </sectiondiv>
    </section>


    <section id="rebootCompute"><title outputclass="headerH">Rebooting Compute Nodes</title>
      <sectiondiv outputclass="insideSection">
        <p>To reboot a compute node the following operations will need to be performed:</p>
        <ul>
          <li>Disable provisioning of the node to take the node offline to prevent further instances
            being scheduled to the node during the reboot. </li>
          <li>Identify instances that exist on the compute node, and then either: <ul>
              <li>Live migrate the instances off the node before actioning the reboot. OR </li>
              <li>Stop the instances</li>
            </ul>
          </li>
          <li>Reboot the node </li>
          <li>Restart the Nova services </li>
          <li>Restart any instances stopped above</li>
        </ul>
        <ol>
          <li>Disable provisioning:
            <codeblock>nova service-disable --reason "&lt;describe reason>" &lt;node name> nova-compute</codeblock>If
            the node has existing instances running on it these instances will need to be migrated
            or stopped prior to re-booting the node.</li>
          <li> Live migrate existing instances. Identify the instances on the compute node. Note:
            The following command must be run with nova admin
            credentials.<codeblock>nova list --host &lt;hostname&gt; --all-tenants</codeblock></li>
          <li> Migrate or Stop the instances on the compute node. <p> Migrate the instances off the
              node by running one of the following commands for each of the instances:</p><p>Until
              HOS 3.0 that will be based on the Mitaka release, the only live-migration cases that
              will work are the following:</p><p>If your instance is booted from a volume and has
              any number of Cinder volume attached, use the nova live-migration
            command:</p><codeblock>nova live-migration &lt;instance uuid&gt; [&lt;target compute host&gt;]</codeblock>
            If your instance has local (ephemeral) disk(s) only, you can use the --block-migrate
            option:<codeblock>nova live-migration --block-migrate &lt;instance uuid&gt; [&lt;target compute host&gt;]</codeblock>
            Note: The [&lt;target compute host&gt;] option is optional. If you do not specify a
            target host then the nova scheduler will choose a node for you.<p>OR</p><p>Stop the
              instances on the node by running the following command for each of the
            instances:</p><codeblock>nova stop &lt;instance-uuid&gt;</codeblock></li>
          <li>Stop all services on the controller node:
            <codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts hlm-stop.yml --limit &lt;compute node></codeblock>
          </li>
          <li>SSH to your Compute nodes and reboot them: <codeblock>reboot</codeblock>
            <p>The operating system cleanly shuts down services and then automatically reboots. If
              you want to be very thorough, run your backup jobs just before you reboot.</p>
          </li>
          <li>Run the hlm-start.yml playbook from the lifecycle manager. If needed, use the
            bm-power-up.yml playbook to restart the node. Specify just the node(s) you want to start
            in the 'nodelist' parameter arguments, i.e.
            nodelist=&lt;node1&gt;[,&lt;node2&gt;][,&lt;node3&gt;].<codeblock>cd ~/helion/hos/ansible
~/helion/hos/ansible$ ansible-playbook -i hosts/localhost bm-power-up.yml -e nodelist=&lt;compute node></codeblock>
          </li>
          <li>Execute the <b>hlm-start.yml </b>playbook. Specifying the node(s) you want to start in
            the 'limit' parameter arguments. This parameter accepts wildcard arguments and also
            '@&lt;filename>' to process all hosts listed in the file.
            <codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts hlm-start.yml --limit &lt;compute node></codeblock>
          </li>
          <li> Restart any instances you
            stopped.<codeblock>nova start &lt;instance-uuid></codeblock>
          </li>

        </ol>
      </sectiondiv>
    </section>
    <section id="rebootControllers"><title outputclass="headerH">Rebooting Controller Nodes</title>
      <sectiondiv outputclass="insideSection"><p>In order to reboot the controller nodes, you must
          first retrieve a list of nodes in your cloud running control plane services.</p>
        <b>TODO: Either put info here or point to existing section on this</b>. <p>After retrieving
          this list, to begin reboot of the controller nodes follow these steps:</p>
        <ol>
          <li>Stop all services on the controller node:
            <codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts hlm-stop.yml --limit &lt;controller node></codeblock>
          </li>
          <li>Reboot the controller node, e.g. run the following command on the controller itself: <codeblock>sudo reboot</codeblock>
            <p>Note that the lifecycle manager may be located on a controller node.</p>
          </li>
          <li>Wait for the controller node to become ssh-able and allow an additional minimum of
            five minutes for the controller node to settle. Start all services on the controller
            node:
            <codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts hlm-start.yml --limit &lt;controller node></codeblock>
          </li>
          <li>When above start operation has completed successfully, you may proceed onto the next
            controller node. </li>
        </ol>
        <note>It is important that you do not begin the reboot procedure for a new controller node
          until the reboot of the previous controller node has been completed successfully (i.e. the
          hlm-start playbook has completed without error). </note>
      </sectiondiv>
    </section>


    <section><title outputclass="headerH">Rebooting Swift Nodes</title>
      <sectiondiv outputclass="insideSection">If your Swift services are on controller node, please
        follow the controller node reboot instructions above. <p>For a dedicated Swift PAC cluster
          or Swift Object resource node: </p>For each Swift host <ol>
          <li>Stop all services on the Swift node:
            <codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts hlm-stop.yml --limit &lt;swift node></codeblock>
          </li>
          <li>Reboot the controller node by running the following command on the controller itself:
            <codeblock>sudo reboot</codeblock>
          </li>
          <li>Wait for the node to become ssh-able and then start all services on the controller
            node:
            <codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts hlm-start.yml --limit &lt;swift node> </codeblock>
          </li>
        </ol>
      </sectiondiv>
    </section>


    <section id="esx"><title>Further ESX Model Upgrade Instructions</title>
      <p>Once you have completed the initial upgrade instructions, you must follow these additional
        steps for ESX deployments:</p>
      <ol>
        <li>The new cluster import can be performed directly with the command below on the already
          activated Data center (DC):
          <codeblock>eon cluster-import --vcenter-id &lt;vcenter-id> --cluster-name &lt;cluster-name> --cluster-moid &lt;MOID of cluster></codeblock></li>
        <li>If the cluster activation is on a new DC, follow the steps below before performing the
          cluster-import: <note>Provide the correct eth interface details for
              <codeph>data_interface_order</codeph> and <codeph>trunk_interface_order</codeph>
            parameters as per the defined input model. Refer to <xref
              href="#install_esx/register-network" format="dita">Register ESX Cloud Network
              Configuration</xref> for more details.</note><ol>
            <li>Get the new <codeph>net-conf.json</codeph> template using the following command:
              <codeblock>eon get-network-info-template -filename net-conf.json</codeblock></li>
            <li>Edit the <codeph>net-conf.json</codeph> file with your lifecycle manager and
              Management network details.</li>
            <li>Uncomment the data network parameters and provide the Data network details. Change
              the <codeph>data_interface_order</codeph> to <codeph>eth2</codeph>. <p>Example:</p>
              <codeblock>"data_interface_order" = eth2</codeblock></li>
            <li>In the Trunk network, change the <codeph>trunk_interface_order</codeph> to
                <codeph>eth3</codeph>. <p>Example:</p>
              <codeblock>"trunk_interface_order" = eth3</codeblock></li>
            <li>Edit the template name and SSH key parameters as needed and save the
                <codeph>net-conf.json</codeph> file.</li>
            <li>Now set these values on the new Data center. This will create new dvSwitches as per
              the <codeph>net-conf.json</codeph> file for the new DC:
              <codeblock>eon set-network-info --vcenter-id &lt;vcenter-id>  --datacenter-name &lt;New DC name> --config-json net_conf.json</codeblock></li>
            <li>Perform the cluster activation on this new DC with the following command:
              <codeblock>eon cluster-import --vcenter-id &lt;vcenter-id> --cluster-name &lt;cluster-name> --cluster-moid &lt;MOID of cluster></codeblock></li>
            <li>Activate the imported cluster:
              <codeblock>eon cluster-activate --vcenter-id &lt;vcenter-id>  --cluster-moid &lt;MOID of cluster></codeblock></li>
            <li>Run the configuration processor:
              <codeblock>cd ~/hellion/hos/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml</codeblock></li>
            <li>Run the ready deployment playbook:
              <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost ready-deployment.yml</codeblock></li>
            <li>Run the site.yml playbook for the ESX proxy Compute nodes and the OVSvAPPs:
              <codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts site.yml --limit '*esx-ovsvapp:*esx-compute'</codeblock></li>
          </ol></li>
      </ol>
    </section>
  </body>
</topic>
