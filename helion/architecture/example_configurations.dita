<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="example_configurations">
  <title><ph conkeyref="HOS-conrefs/product-title"/>Example Configurations</title>
  <body>
    <p conkeyref="HOS-conrefs/applies-to"/>
    <p>The <keyword keyref="kw-hos-phrase"/> system ships with a collection of pre-qualified example
      configurations. These are designed to help you to get up and running quickly with a minimum
      number of configuration changes.</p>
    <p>The <keyword keyref="kw-hos"/> input model allows a wide variety of configuration parameters
      that may, at first glance, appear daunting. The example configurations are designed to
      simplify this process by providing pre-built and pre-qualified examples that need only a
      minimum number of modifications to get started.</p>
    <section id="contents">
      <ul>
        <li><xref href="example_configurations.dita#example_configurations/example_configs">
            <keyword keyref="kw-hos"/> Example Configurations</xref>
          <ul>
            <li><xref keyref="entryscale_kvm_vsa">Entry-Scale KVM with VSA Model</xref></li>
            
            <li><xref keyref="entryscale_kvm_dedicated">Entry-scale KVM with VSA model with Dedicated Cluster for Metering, Monitoring, and
                Logging</xref></li>
            <li><xref keyref="entryscale_esx">Entry-Scale ESX Model</xref></li>
            <li><xref keyref="entryscale_swift">Entry-Scale Swift Model</xref></li>
            <li><xref keyref="entryscale_ceph">Entry-Scale KVM with Ceph Model</xref></li>
            <li><xref keyref="midscale_kvm_vsa">Mid-Scale KVM with VSA Model</xref></li>
          </ul>
        </li>

       <li><xref keyref="alternative_configurations">Alternative Configurations</xref>
          <ul>
            <li><xref keyref="entryscale_ceph_multinetwork">Entry-Scale KVM with Ceph Model with Two Networks</xref>
              <!--<ul>
                <li><xref href="example_configurations.dita#example_configurations/ceph_nicmappings"
                    >Nic_mappings.yml</xref></li>
                <li><xref
                    href="example_configurations.dita#example_configurations/ceph_netinterfaces"
                    >Net_interfaces.yml</xref></li>
                <li><xref
                    href="example_configurations.dita#example_configurations/ceph_networksgroups"
                    >Network_groups.yml</xref></li>
                <li><xref href="example_configurations.dita#example_configurations/ceph_networks"
                    >Networks.yml</xref></li>
                <li><xref
                    href="example_configurations.dita#example_configurations/ceph_servergroups"
                    >Server_groups.yml</xref></li>
                <li><xref
                    href="example_configurations.dita#example_configurations/ceph_firewallrules"
                    >Firewall_rules.yml</xref></li>
                <li><xref href="example_configurations.dita#example_configurations/ceph_readme">Edit
                    the README.html and README.md Files</xref></li>
              </ul>-->
            </li>
            <li><xref keyref="entryscale_kvm_ceph_threenetwork">Entry-Scale KVM with Ceph Model with Three Networks</xref>
              <!--<ul>
                <li><xref
                    href="example_configurations.dita#example_configurations/ceph3_nicmappings"
                    >Nic_mappings.yml</xref></li>
                <li><xref href="example_configurations.dita#example_configurations/ceph3_servers"
                    >Servers.yml</xref></li>
                <li><xref
                    href="example_configurations.dita#example_configurations/ceph3_netinterfaces"
                    >Net_interfaces.yml</xref></li>
                <li><xref
                    href="example_configurations.dita#example_configurations/ceph3_networkgroups"
                    >Network_groups.yml</xref></li>
                <li><xref href="example_configurations.dita#example_configurations/ceph3_networks"
                    >Networks.yml</xref></li>
                <li><xref
                    href="example_configurations.dita#example_configurations/ceph3_servergroups"
                    >Server_groups.yml</xref></li>
                <li><xref
                    href="example_configurations.dita#example_configurations/ceph3_firewallrules"
                    >Firewall_rules.yml</xref></li>
                <li><xref href="example_configurations.dita#example_configurations/ceph3_readme"
                    >Edit the README.html and README.md Files</xref></li>
              </ul>-->
            </li>
          </ul>
        </li>

        <li><xref
            keyref="modify_entryscale_kvm_vsa"
            >Modifying the Entry-scale KVM with VSA Model for Your Environment</xref>
       <ul>
            <li><xref keyref="localizing_inputmodel">Localizing the Input Model</xref>
              <!--<ul>
                <li><xref href="example_configurations.dita#example_configurations/networks"
                    >Networks.yml</xref></li>
                <li><xref href="example_configurations.dita#example_configurations/nicmappings"
                    >Nic_mappings.yml</xref></li>
                <li><xref href="example_configurations.dita#example_configurations/netinterfaces"
                    >Net_interfaces.yml</xref></li>
                <li><xref href="example_configurations.dita#example_configurations/networkgroups"
                    >Network_groups.yml</xref></li>
                <li><xref href="example_configurations.dita#example_configurations/servers"
                    >Servers.yml</xref></li>
              </ul>-->
            </li>
            <li><xref keyref="customizing_inputmodel">Customizing the Input Model</xref>
              <!--<ul>
                <li><xref href="example_configurations.dita#example_configurations/disks_controller"
                    >Disks_controller.yml</xref>
                  <ul>
                    <li><xref href="example_configurations.dita#example_configurations/filesystems"
                        >File Systems Storage</xref></li>
                    <li><xref href="example_configurations.dita#example_configurations/swiftstorage"
                        >Swift Storage</xref></li>
                  </ul>
                </li>
                <li><xref href="example_configurations.dita#example_configurations/disks_vsa"
                    >Disks_vsa.yml</xref></li>
                <li><xref href="example_configurations.dita#example_configurations/disks_compute"
                    >Disks_compute.yml</xref></li>
              </ul>-->
            </li>
            <li><xref keyref="standalone_deployer">Using a
                Standalone Lifecycle-Manager Node</xref>
              <!--<ul>
                <li><xref
                    href="example_configurations.dita#example_configurations/control_plane_yml"
                    >Control_plane.yml</xref></li>
                <li><xref href="example_configurations.dita#example_configurations/server_roles_yml"
                    >Server_roles.yml</xref></li>
                <li><xref
                    href="example_configurations.dita#example_configurations/net_interfaces_yml"
                    >Net_interfaces.yml</xref></li>
                <li><xref
                    href="example_configurations.dita#example_configurations/disks_lifecycle_manager_yml"
                    >Disks_lifecycle_manager.yml</xref></li>
                <li><xref href="example_configurations.dita#example_configurations/servers_yml"
                    >Servers.yml</xref></li>
              </ul>-->
            </li>
            <li><xref href="example_configurations.dita#example_configurations/without_dvr"
                >Configuring <keyword keyref="kw-hos"/> without DVR</xref></li>
            <li><xref href="example_configurations.dita#example_configurations/without_l3agent"
                >Configuring <keyword keyref="kw-hos"/> with Provider VLANs and Physical Routers
                Only</xref></li>
            <li><xref href="example_configurations.dita#example_configurations/twosystems"
                >Considerations When Installing Two Systems on One Subnet</xref></li>
          </ul>
        </li>

      </ul>
    </section>
    <section id="example_configs"><title><keyword keyref="kw-hos"/> Example Configurations</title>
      <p>This section briefly describes the various example configurations and their capabilities.
        It also describes in detail, for the entry-scale-kvm-vsa example, how you can adapt the
        input model to work in your environment.</p>
      <!--<p><keyword keyref="kw-hos-phrase"/> ships with two classes of sample cloud models: examples
        and tech-preview. The models in the examples directory have been qualified by our Quality
        Engineering team, while the tech-preview models are more experimental.</p>-->
      <p>The following pre-qualified examples are shipped with <keyword keyref="kw-hos-phrase"
        />:</p>
      
      
      <table frame="all" rowsep="1" colsep="1" id="table_examples">
        <tgroup cols="2">
          <colspec colname="c1" colnum="1"/>
          <colspec colname="c2" colnum="2"/>
          <thead>
            <row>
              <entry>Name</entry>
              <entry>Location</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry><xref keyref="entryscale_kvm_vsa">Entry-scale KVM with VSA model</xref></entry>
              <entry><codeph>~/helion/examples/entry-scale-kvm-vsa</codeph></entry>                           
            </row>
            <row>
              <entry><xref keyref="entryscale_kvm_dedicated">Entry-scale KVM with VSA model with Dedicated Cluster for Metering, Monitoring, and
                Logging</xref> </entry>
              <entry><codeph>~/helion/examples/entry-scale-kvm-vsa-mml</codeph></entry>                           
            </row>
            <row>
              <entry><xref keyref="entryscale_swift">Entry-scale Swift-only model</xref></entry>
              <entry><codeph>~/helion/examples/entry-scale-swift</codeph></entry>                           
            </row>
            <row>
              <entry><xref keyref="entryscale_ceph_multinetwork">Entry-scale KVM with Ceph model</xref></entry>
              <entry><codeph>~/helion/examples/entry-scale-kvm-ceph</codeph></entry>                           
            </row>
            <row>
              <entry><xref keyref="entryscale_esx">Entry-scale ESX model</xref></entry>
              <entry><codeph>~/helion/examples/entry-scale-esx</codeph></entry>                           
            </row>
            <row>
              <entry><xref keyref="midscale_kvm_vsa">Mid-scale KVM with VSA model</xref></entry>
              <entry><codeph>~/helion/examples/mid-scale-kvm-vsa</codeph></entry>                           
            </row>
            
            
          </tbody>
        </tgroup>
      </table>

      <p>The entry-scale systems are designed to provide an entry-level solution that can be scaled
        from a small number of nodes to a moderately high node count (approximately 100 compute
        nodes, for example).</p>
      <p>In the mid-scale model, the cloud control plane is subdivided into a number of dedicated
        service clusters to provide more processing power for individual control plane elements.
        This enables a greater number of resources to be supported (compute nodes, Swift object
        servers). This model also shows how a segmented network can be expressed in the <keyword
          keyref="kw-hos"/> model.</p>
    </section>
    
    





<!--
    <section id="alternative"><title>Alternative Configurations</title>
      <p>In <keyword keyref="kw-hos-phrase"/> there are alternative configurations that we recommend
        for specific purposes and this section we will outline them.</p>
    </section>
-->







    

    <section id="without_dvr"><title>Configuring <keyword keyref="kw-hos"/> without DVR</title>
      <p>By default in the KVM model, the Neutron service utilizes distributed routing (DVR). This
        is the recommended setup because it allows for high availability. However, if you would like
        to disable this feature, here are the steps to achieve this.</p>
      <p>On your lifecycle manager, make the following changes:</p>
      <ol>
        <li>In the <codeph>~/helion/my_cloud/config/neutron/neutron.conf.j2</codeph> file, change
          the line below from: <codeblock>router_distributed = {{ router_distributed }}</codeblock>
          <p>to:</p>
          <codeblock>router_distributed = False</codeblock></li>
        <li>In the <codeph>~/helion/my_cloud/config/neutron/ml2_conf.ini.j2</codeph> file, change
          the line below from: <codeblock>enable_distributed_routing = True</codeblock>
          <p>to:</p>
          <codeblock>enable_distributed_routing = False</codeblock></li>
        <li>In the <codeph>~/helion/my_cloud/config/neutron/l3_agent.ini.j2</codeph> file, change
          the line below from: <codeblock>agent_mode = {{ neutron_l3_agent_mode }}</codeblock>
          <p>to:</p>
          <codeblock>agent_mode = legacy</codeblock></li>
        <li>In the <codeph>~/helion/my_cloud/definition/data/control_plane.yml</codeph> file, remove
          the following values from the Compute resource <codeph>service-components</codeph> list:
          <codeblock>
   - neutron-l3-agent
   - neutron-metadata-agent</codeblock></li>
      </ol>
    </section>

    <section id="without_l3agent"><title>Configuring <keyword keyref="kw-hos"/> with Provider VLANs
        and Physical Routers Only</title>
      <p>Another option for configuring Neutron is to use provider VLANs and physical routers only,
        here are the steps to achieve this.</p>
      <p>On your lifecycle manager, make the following changes:</p>
      <ol>
        <li>In the <codeph>~/helion/my_cloud/config/neutron/neutron.conf.j2</codeph> file, change
          the line below from: <codeblock>router_distributed = {{ router_distributed }}</codeblock>
          <p>to:</p>
          <codeblock>router_distributed = False</codeblock></li>
        <li>In the <codeph>~/helion/my_cloud/config/neutron/ml2_conf.ini.j2</codeph> file, change
          the line below from: <codeblock>enable_distributed_routing = True</codeblock>
          <p>to:</p>
          <codeblock>enable_distributed_routing = False</codeblock></li>
        <li>In the <codeph>~/helion/my_cloud/config/neutron/dhcp_agent.ini.j2</codeph> file, change
          the line below from: <codeblock>enable_isolated_metadata = {{ neutron_enable_isolated_metadata }}</codeblock>
          <p>to:</p>
          <codeblock>enable_isolated_metadata = True</codeblock></li>
        <li>In the <codeph>~/helion/my_cloud/definition/data/control_plane.yml</codeph> file, remove
          the following values from the Compute resource <codeph>service-components</codeph> list:
          <codeblock>
  - neutron-l3-agent
  - neutron-metadata-agent</codeblock></li>
      </ol>
    </section>
 
    <section id="twosystems"><title>Considerations When Installing Two Systems on One Subnet</title>
      <p>If you wish to install two separate <ph conkeyref="HOS-conrefs/product-title"/> systems
        using a single subnet, you will need to consider the following notes.</p>
      <p>The <codeph>ip_cluster</codeph> service includes the <codeph>keepalived</codeph> daemon
        which maintains virtual IPs (VIPs) on cluster nodes. In order to maintain VIPs, it
        communicates between cluster nodes over the VRRP protocol.</p>
      <p>A VRRP virtual routerid identifies a particular VRRP cluster and must be unique for a
        subnet. If you have two VRRP clusters with the same virtual routerid, causing a clash of
        VRRP traffic, the VIPs are unlikely to be up or pingable and you are likely to get the
        following signature in your <codeph>/etc/keepalived/keepalived.log</codeph>:</p>
      <codeblock>Dec 16 15:43:43 helion-cp1-c1-m1-mgmt Keepalived_vrrp[2218]: ip address associated with VRID not present in received packet : 10.2.1.11
Dec 16 15:43:43 helion-cp1-c1-m1-mgmt Keepalived_vrrp[2218]: one or more VIP associated with VRID mismatch actual MASTER advert
Dec 16 15:43:43 helion-cp1-c1-m1-mgmt Keepalived_vrrp[2218]: bogus VRRP packet received on br-bond0 !!!
Dec 16 15:43:43 helion-cp1-c1-m1-mgmt Keepalived_vrrp[2218]: VRRP_Instance(VI_2) ignoring received advertisment...</codeblock>
      <p>To resolve this issue, our recommendation is to install your separate <ph
          conkeyref="HOS-conrefs/product-title"/> systems with VRRP traffic on different
        subnets.</p>
      <p>If this is not possible, you may also assign a unique routerid to your separate <ph
          conkeyref="HOS-conrefs/product-title"/> system by changing the
          <codeph>keepalived_vrrp_offset</codeph> service configurable. The routerid is currently
        derived using the <codeph>keepalived_vrrp_index</codeph> which comes from a configuration
        processor variable and the <codeph>keepalived_vrrp_offset</codeph>.</p>
      <p>For example, </p>
      <ol>
        <li>Log in to your lifecycle manager.</li>
        <li>Edit your <codeph>~/helion/my_cloud/config/keepalived/defaults.yml</codeph> file and
          change the value of the following line: <codeblock>keepalived_vrrp_offset: 0</codeblock>
          <p>Change the off value to a number that uniquely identifies a separate vrrp cluster. For
            example:</p>
          <p><codeph>keepalived_vrrp_offset: 0</codeph> for the 1st vrrp cluster on this subnet.</p>
          <p><codeph>keepalived_vrrp_offset: 1</codeph> for the 2nd vrrp cluster on this subnet.</p>
          <p><codeph>keepalived_vrrp_offset: 2</codeph> for the 3rd vrrp cluster on this
          subnet.</p></li>
        <li>Commit your configuration to the <xref href="../installation/using_git.dita">local git
            repo</xref>, as follows:
          <codeblock>cd ~/helion/hos/ansible
git add -A
git commit -m "changing Admin password"</codeblock></li>
        <li>Run the configuration processor with this command:
          <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml</codeblock></li>
        <li>Use the playbook below to create a deployment directory:
          <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost ready-deployment.yml</codeblock></li>
        <li>If you are making this change after your initial install, run the following reconfigure
          playbook to make this change in your environment:
          <codeblock>cd ~/scratch/ansible/next/hos/ansible/
ansible-playbook -i hosts/verb_hosts FND-CLU-reconfigure.yml
        </codeblock></li>
      </ol>
    </section>
 
  
  </body>
</topic>
