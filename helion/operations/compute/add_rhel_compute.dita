<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="topic_yy5_bwz_lv">
  <title><ph conkeyref="HOS-conrefs/product-title"/>Adding a RHEL Compute Node</title>
  <abstract><shortdesc outputclass="hdphidden">Adding a RHEL compute node allows you to add additional
    capacity for more virtual machines.</shortdesc><p>You may have a need to add an additioanl RHEL compute node for additional virtual
      machine capacity or another purpose and these steps will help you achieve this.</p></abstract>
  <body>
    <section id="notes"><title>Notes</title>
      <p>There are two methods you can use to add RHEL compute hosts to your environment:</p>
      <ol>
        <li>Using the provided Ansible playbooks and Cobbler, RHEL will be installed on your new
          compute hosts. This method requires that you provided a RHEL 7.2 iso during the initial
          installation of your cloud, following the instructions at {{PROVIDE LINK}}.</li>
        <li>Adding RHEL pre-installed compute hosts. This method does not require the RHEL iso be on
          the lifecycle manager to complete.</li>
      </ol>
    </section>
    
    <section id="prereqs"><title>Prerequisites</title>
      <p>You need to ensure your input model files are properly setup for RHEL compute host clusters.</p>
          </section>
    
    <section id="steps"><title>Adding a RHEL Compute Node</title>
      <p>These steps will show you how to add the new
        RHEL compute node to your <codeph>servers.yml</codeph> file and then run the playbooks that
        update your cloud configuration. You will run these playbooks from the lifecycle
        manager.</p>
        <ol>
          <li>Log in to your lifecycle manager.</li>
          <li>Checkout the <codeph>site</codeph> branch of your local git so you can begin to make
            the necessary edits:
            <codeblock>cd ~/helion/my_cloud/definition/data
              git checkout site</codeblock></li>
          <li>Edit your <codeph>~/helion/my_cloud/definition/data/servers.yml</codeph> file to
            include the details about your new compute node(s). <p>For example, if you already had a
              cluster of three compute nodes and needed to add a fourth one you would add your
              details to the bottom of the file in this format:</p>
            <codeblock>
- id: compute4
  ip-addr: 192.168.102.70
  role: RHEL-COMPUTE-ROLE
  server-group: RACK1
  mac-addr: e8:39:35:21:32:4e
  ilo-ip: 10.1.192.36
  ilo-password: password
  ilo-user: admin
  distro-id: rhel72-x86_64</codeblock>
            <p>You can find detailed descriptions of these fields <xref
              keyref="configobj_servers">here</xref>.</p>
            <note type="important">You will need to verify that the <codeph>ip-addr</codeph> value
              you choose for this node does not conflict with any other IP address in your cloud
              environment. You can confirm this by checking the
              <codeph>~/helion/my_cloud/info/address_info.yml</codeph> file on your lifecycle
              manager.</note>
          </li>
          <li>In your <codeph>~/helion/my_cloud/definition/data/control_plane.yml</codeph> file you
            will need to check the values for <codeph>member-count</codeph>,
            <codeph>min-count</codeph>, and <codeph>max-count</codeph>. If you specified them,
            ensure that they match up with your new total node count. For example, if you had
            previously specified <codeph>member-count: 3</codeph> and are adding a fourth compute
            node, you will need to change that value to <codeph>member-count: 4</codeph>. <p>See
              <xref keyref="configobj_controlplane">Input Model - Control
                Plane</xref> for more details.</p></li>
          <li>Commit the changes to git:
            <codeblock>git add -A
git commit -a -m "Add node &lt;name>"</codeblock></li>
          <li>Run the configuration processor:
            <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml</codeblock></li>
          <li>Run the ready deployment playbook:
            <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost ready-deployment.yml</codeblock></li>
          <li>Add the new node into Cobbler:
            <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost cobbler-deploy.yml</codeblock></li>
          <li>Then you can image the node: <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost bm-reimage.yml -e nodelist=&#60;node name></codeblock>
            <note>If you don't know the <codeph>&#60;node name></codeph> already, you can get it by
              using <codeph>sudo cobbler system list</codeph></note>
            <p>Before proceeding, you may want to take a look at <b>info/server_info.yml</b> to see
              if the assignment of the node you have added is what you expect. It may not be, as
              nodes will not be numbered consecutively if any have previously been removed. This is
              to prevent loss of data; the config processor retains data about removed nodes and
              keeps their ID numbers from being reallocated. See the Persisted Server Allocations
              section in <xref keyref="persisteddata/persistedserverallocations"
                >Input Model</xref> for information on how this works.</p></li>
          <li>Complete the RHEL compute deployment with this playbook:
            <codeblock>cd ~/scratch/ansible/next/hos/ansible/
ansible-playbook -i hosts/verb_hosts site.yml --limit &#60;node name></codeblock></li>
        </ol>
    </section>
    
    <section id="monitoring"><title outputclass="headerH">Adding a New RHEL Compute Node to
      Monitoring</title>
        <p>If you want to add a new Compute node to the monitoring service checks, there is an
          additional playbook that must be run to ensure this happens:</p>
        <codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts monasca-deploy.yml --tags active_ping_checks</codeblock>
    </section>
    

    <section id="inputmodel"><title>Input Model File Changes</title>
      <p><b>net_interfaces.yml</b></p>
      <p>
        <codeblock>
- name: RHEL-COMPUTE-INTERFACES
  network-interfaces:
     - name: BOND0
       device:
          name: bond0
       bond-data:
          options:
             mode: active-backup
             miimon: 200
             primary: hed1
          provider: linux
          devices:
             - name: hed1
             - name: hed2
       network-groups:
         - EXTERNAL-VM
         - GUEST
         - MANAGEMENT</codeblock>
      </p>
      <p><b>servers.yml</b></p>
 
      <p><b>server_roles.yml</b></p>
      <codeblock>
- name: RHEL-COMPUTE-ROLE
  interface-model: RHEL-COMPUTE-INTERFACES
  disk-model: RHEL-COMPUTE-DISKS</codeblock>
      <p><b>disks_compute.yml</b></p>
      <codeblock>
- name: RHEL-COMPUTE-DISKS
  volume-groups:
    - name: rhel
      physical-volumes:
        - /dev/sda2
      logical-volumes:
        - name: root
          size: 55%
          fstype: xfs
          mount: /
        - name: log
          size: 35%
          mount: /var/log
          fstype: ext4
          mkfs-opts: -O large_file
    - name: vg-comp
      physical-volumes:
        - /dev/sdb
      logical-volumes:
        - name: compute
          size: 95%
          mount: /var/lib/nova
          fstype: ext4
          mkfs-opts: -O large_file</codeblock>
      <p><b>control_plane.yml</b></p>
      <codeblock>
- name: rhel-compute
  resource-prefix: rhel-comp
  server-role: RHEL-COMPUTE-ROLE
  allocation-policy: any
  min-count: 0
  service-components:
     - ntp-client
     - nova-compute
     - nova-compute-kvm
     - neutron-l3-agent
     - neutron-metadata-agent
     - neutron-openvswitch-agent
     - neutron-lbaasv2-agent</codeblock>
    </section>

    <section id="steps2"><title>Steps</title>
      <p>After making the changes to your input model files for your new RHEL compute nodes, follow
        these steps:</p>
      <ol>
        <li>Commit the changes to git:
          <codeblock>git add -A
git commit -a -m "Add node &lt;name>"</codeblock></li>
        <li>Run the configuration processor:
          <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost config-processor-run.yml</codeblock></li>
        <li>Run the ready deployment playbook:
          <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost ready-deployment.yml</codeblock></li>
        <li>Add the new node into Cobbler:
          <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost cobbler-deploy.yml</codeblock></li>
        <li>Then you can image the node: <codeblock>cd ~/helion/hos/ansible
ansible-playbook -i hosts/localhost bm-reimage.yml -e nodelist=&#60;node name></codeblock>
          <note>If you don't know the <codeph>&#60;node name></codeph> already, you can get it by
            using <codeph>sudo cobbler system list</codeph></note>
          <p>Before proceeding, you may want to take a look at <b>info/server_info.yml</b> to see if
            the assignment of the node you have added is what you expect. It may not be, as nodes
            will not be numbered consecutively if any have previously been removed. This is to
            prevent loss of data; the config processor retains data about removed nodes and keeps
            their ID numbers from being reallocated. See the Persisted Server Allocations section in
              <xref keyref="persisteddata/persistedserverallocations">Input Model</xref> for
            information on how this works.</p></li>
        <li>Complete the RHEL compute deployment with this playbook:
          <codeblock>cd ~/scratch/ansible/next/hos/ansible/
            ansible-playbook -i hosts/verb_hosts site.yml --limit &#60;node name></codeblock>
        </li>
      </ol>
    </section>
  </body>
</topic>
