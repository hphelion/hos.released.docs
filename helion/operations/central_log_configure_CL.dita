<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic
  PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd" >
<topic xml:lang="en-us" id="central_log_configure_settings">
  <title>Settings for Centralized Logging</title>
  <body>
    <!--not tested-->
    <section id="Clog_config_settings">
      <p>Text</p>
      <ul>
        <li><xref href="#central_log_configure_settings/CL_config_files">Where Can I Find the Configuration Files?</xref></li>
        <li><xref href="#central_log_configure_settings/CL_general_config">How Do I Set Disk Space Limits?</xref></li>
        <li><xref href="#central_log_configure_settings/CL_BU_Elasticsearch">How Do I Back-Up the Files to Elasticsearch?</xref></li>
      </ul>
    </section>


    <section id="CL_config_files"><title>Where Can I Find the Configuration Files?</title>
      <p>Centralized Logging can be configured via the configuration files in the
          <codeph>~/helion/my_cloud/config/logging/</codeph> directory on the lifecycle manager.
        These files and their use are described below:</p>
      <table frame="all" rowsep="1" colsep="1" id="table_wtv_rc5_st">
        <tgroup cols="2">
          <colspec colname="c1" colnum="1"/>
          <colspec colname="c2" colnum="2"/>
          <thead>
            <row>
              <entry>File</entry>
              <entry>Description</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>main.yml</entry>
              <entry>Main configuration file for all centralized logging components.</entry>
            </row>
            <row>
              <entry>elasticsearch.yml.j2</entry>
              <entry>Main configuration file for Elasticsearch.</entry>
            </row>
            <row>
              <entry>elasticsearch-default.j2</entry>
              <entry>Default overrides for the Elasticsearch init script.</entry>
            </row>
            <row>
              <entry>kibana.yml.j2</entry>
              <entry>Main configuration file for Kibana.</entry>
            </row>
            <row>
              <entry>kibana-apache2.conf.j2</entry>
              <entry>Apache configuration file for Kibana.</entry>
            </row>
            <row>
              <entry>logstash.conf.j2</entry>
              <entry>Logstash inputs/outputs configuration.</entry>
            </row>
            <row>
              <entry>logstash-default.j2</entry>
              <entry>Default overrides for the Logstash init script.</entry>
            </row>
            <row>
              <entry>beaver.conf.j2</entry>
              <entry>Main configuration file for Beaver.</entry>
            </row>
            <row>
              <entry>vars</entry>
              <entry>Path to logrotate configuration files.</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>
<lines>
  
  
</lines>
    <section id="CL_general_config">
      <title>How Do I Set Disk Space Limits?</title>
      <p>The Centralized Logging service needs to have enough resources available to it to perform
        adequately for different scale environments. The base logging levels are tuned during
        installation according to the amount of RAM allocated to your control plane nodes to ensure
        optimum performance.</p>
      <table frame="all" rowsep="1" colsep="1" id="table_grx_2f5_st">
        <tgroup cols="7">
          <colspec colname="c1" colnum="1"/>
          <colspec colname="c2" colnum="2"/>
          <colspec colname="c3" colnum="3"/>
          <colspec colname="c4" colnum="4"/>
          <colspec colname="c5" colnum="5"/>
          <colspec colname="c6" colnum="6"/>
          <colspec colname="newCol7" colnum="7" colwidth="1*"/>
          <thead>
            <row>
              <entry>Component</entry>
              <entry>Ansible Variable</entry>
              <entry>Demo (&lt;32 GB)</entry>
              <entry>Small (&lt;64 GB)</entry>
              <entry>Medium (&lt;128 GB)</entry>
              <entry>Large (>= 128 GB)</entry>
              <entry>Description</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>Elasticsearch</entry>
              <entry>elasticsearch_heap_size</entry>
              <entry>256 MB</entry>
              <entry>8 GB</entry>
              <entry>16 GB</entry>
              <entry>32 GB</entry>
              <entry>Amount of heap allocated to Elasticsearch.</entry>
            </row>
            <row>
              <entry>Logstash</entry>
              <entry>logstash_heap_size</entry>
              <entry>256 MB</entry>
              <entry>2 GB</entry>
              <entry>4 GB</entry>
              <entry>8 GB</entry>
              <entry>Amount of heap allocated to Logstash.</entry>
            </row>
            <row>
              <entry>Logstash</entry>
              <entry>logstash_num_workers</entry>
              <entry>10 threads</entry>
              <entry>10 threads</entry>
              <entry>20 threads</entry>
              <entry>30 threads</entry>
              <entry>Number of Logstash threads to spawn.</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
      <p>These values can be viewed and changed in the
          <codeph>~/helion/my_cloud/config/logging/main.yml</codeph> file, but you will need to run
        a reconfigure of the Centralized Logging service if changes are made.</p>
      <note type="warning">The total process memory consumption for Elasticsearch will be the above
        allocated heap value plus any Java Virtual Machine (JVM) overhead.</note>
      <p><b>Disk Size Requirements</b></p>
      <p>In the entry-scale models, the disk partition sizes on your controller nodes for the
        logging and elasticsearch data are set as a percentage of your total disk size. You can see
        these in the following file on the lifecycle manager (deployer):
          <codeph>~/helion/my_cloud/definition/data/disks_controller.yml</codeph>
      </p>
      <p>Sample file settings:</p>
      <codeblock># Local Log files.
- name: log
  size: 13%
  mount: /var/log
  fstype: ext4
  mkfs-opts: -O large_file

# Data storage for centralized logging. This holds log entries from all
# servers in the cloud and hence can require a lot of disk space.
- name: elasticsearch
  size: 30%
  mount: /var/lib/elasticsearch
  fstype: ext4</codeblock>
      <p>Given these percentages, you will want to ensure your total disk size for your controller
        nodes is enough that you meet the following partition size requirements depending on the
        total scale of your environment:</p>
      <table frame="all" rowsep="1" colsep="1" id="table_xld_n31_t5">
        <tgroup cols="4">
          <colspec colname="c1" colnum="1"/>
          <colspec colname="c2" colnum="2"/>
          <colspec colname="c3" colnum="3"/>
          <colspec colname="c4" colnum="4"/>
          <thead>
            <row>
              <entry>Partition</entry>
              <entry>Small Scale</entry>
              <entry>Medium Scale</entry>
              <entry>Large Scale</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>/var/log</entry>
              <entry>200 GB</entry>
              <entry>400 GB</entry>
              <entry>500 GB</entry>
            </row>
            <row>
              <entry>/var/lib/elasticsearch</entry>
              <entry>1.5 TB</entry>
              <entry>3 TB</entry>
              <entry>6 TB</entry>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>
<lines>
  
  
</lines>
    <section id="CL_BU_Elasticsearch">
      <title>How Do I Back-Up the Files to Elasticsearch?</title>
      <p>Text</p>
    </section>

  </body>
</topic>
