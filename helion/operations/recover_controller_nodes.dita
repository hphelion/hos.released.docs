<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="recover_downed_cluster">
  <title><ph conkeyref="HOS-conrefs/product-title"/>Recovering Controller Nodes</title>
  <abstract><shortdesc outputclass="hdphidden">Steps for recovering a single controller node or a
      cluster in your environment.</shortdesc></abstract>
  <body>
    <p conkeyref="HOS-conrefs/applies-to"/>

    <!-- WHEN, WHY -->
    <section>
      <p>These steps will assist in the recovery effort if one or more of your controller nodes lose
        network connectivity or power, which includes if the node is either rebooted or needs
        hardware maintenance.</p>
      <p>These steps may also be used if the Host Status (ping) alarm is triggered for one or more
        of your controller nodes. Here is what the alarm looks like in the Operations Console:</p>
      <image href="../../media/hos.docs/opsconsole_hostalarm.png"/>
    </section>
    <section id="expandCollapse">
      <sectiondiv outputclass="expandall">Expand All Sections</sectiondiv>
      <sectiondiv outputclass="collapseall">Collapse All Sections</sectiondiv>
    </section>

    <!-- HOW, WHO, WHERE -->
    <section id="prereqs"><title outputclass="headerH">Prerequisites</title>
      <sectiondiv outputclass="insideSection">
        <p>The following conditions must be true in order to perform these steps successfully:</p>
        <ul>
          <li>Each of your controller nodes should be powered on.</li>
          <li>Each of your controller nodes should have network connectivity, verified by SSH
            connectivity from the lifecycle manager to them.</li>
          <li>The operator who performs these steps will need access to the lifecycle manager.</li>
        </ul>
      </sectiondiv>
    </section>
    <section id="mysql"><title outputclass="headerH">Recovering the MySQL Database</title>
      <sectiondiv outputclass="insideSection">
        <p>The recovery process for your MySQL database cluster will use the bootstrap command
          described below.</p>
        <p>The node that you perform these steps on should be the last node to go down. So if only
          one of your controller nodes went down, then you would skip to step #2 and run the
          bootstrap commands on that node. If multiple controller nodes went down then you should
          use the instructions in step #1 to determine which was the last node to go down and then
          proceed to run the rest of the steps on that node.</p>
        <ol>
          <li>SSH into each controller node that went down and use the commands below to get the log
            sequence number: <codeblock>sudo /usr/bin/mysqld_safe --wsrep-recover
sudo grep --text 'log sequence number' /var/log/mysql/error.log | tail -1</codeblock>
            <p>Here is an example where I have bolded the log sequence numbers from a three
              controller node cluster:</p>
            <note type="important">In this example, two nodes have the same sequence number which
              means you can run the bootstrap on either node but you can only run the bootstrap
              command once and only on one node.</note>
            <codeblock>stack@helion-cp-c1-m1-mgmt:~$ sudo /usr/bin/mysqld_safe --wsrep-recover
stack@helion-cp-c1-m1-mgmt:~$ sudo grep --text 'log sequence number' /var/log/mysql/error.log | tail -1 
151119 14:37:12 InnoDB: Shutdown completed; log sequence number <b>165002105</b> 
              
stack@helion-cp-c1-m2-mgmt:~$ sudo /usr/bin/mysqld_safe --wsrep-recover
stack@helion-cp-c1-m2-mgmt:~$ sudo grep --text 'log sequence number' /var/log/mysql/error.log | tail -1 
151119 14:53:22 Percona XtraDB (http://www.percona.com) 5.5.41-37.0 started; log sequence number <b>165252407</b>
              
stack@helion-cp-c1-m3-mgmt:~$ sudo /usr/bin/mysqld_safe --wsrep-recover
stack@helion-cp-c1-m3-mgmt:~$ sudo grep --text 'log sequence number' /var/log/mysql/error.log | tail -1 
151119 14:53:22 Percona XtraDB (http://www.percona.com) 5.5.41-37.0 started; log sequence number <b>165252407</b>
151119 14:53:23 InnoDB: Shutdown completed; log sequence number 165252407</codeblock></li>
          <li>SSH into the node with the highest log sequence number and bootstrap the cluster with
            these commands:
            <codeblock>sudo /etc/init.d/mysql bootstrap-pxc
 sudo service mysql restart</codeblock></li>
          <li>Log onto any other controller nodes that went down and run this command to start MySQL
            back up: <codeblock>sudo service mysql start</codeblock>
          </li>
        </ol>
      </sectiondiv>
    </section>

    <section id="vertica"><title outputclass="headerH">Recovering the Vertica Database</title>
      <sectiondiv outputclass="insideSection">
        <p>In order to recover your Vertica databases, run the following playbook:</p>
        <codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts monasca-vertica-recovery.yml</codeblock>
        <p>or if you have encryption enabled, use:</p>
        <codeblock>ansible-playbook -i hosts/verb_hosts monasca-vertica-recovery.yml --ask-vault-pass</codeblock>
      </sectiondiv>
    </section>

    <section id="hlm"><title outputclass="headerH">Restarting Services on the Controller
        Nodes</title>
      <sectiondiv outputclass="insideSection">
        <p>Log in to the lifecycle manager and execute the hlm-start playbook for each node that was
          brought down so the services can be started back up:</p>
        <codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts hlm-start.yml --limit=&lt;hostname&gt;</codeblock>
        <note>If you leave off the <codeph>--limit</codeph> switch, the playbook will be run against
          all nodes.</note>
        <p>Here is an example using the above command using the example in the previous step.</p>
        <codeblock>ansible-playbook -i hosts/verb_hosts hlm-start.yml --limit=helion-cp-c1-m1-mgmt,helion-cp-c1-m2-mgmt,helion-cp-c1-m3-mgmt</codeblock>
      </sectiondiv>
    </section>

    <section id="monasca"><title outputclass="headerH">Restart the Monitoring Agents</title>
      <sectiondiv outputclass="insideSection">
        <p>As part of the recovery process, you shoudl also restart the
            <codeph>monasca-agent</codeph> and these steps will show you how:</p>
        <ol>
          <li>Log in to the lifecycle manager.</li>
          <li>Top the <codeph>monasca-agent</codeph>:
            <codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts monasca-agent-stop.yml</codeblock></li>
          <li>Restart the <codeph>monasca-agent</codeph>:
            <codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts monasca-agent-start.yml</codeblock></li>
          <li>You can then confirm the status of the <codeph>monasca-agent</codeph> with this
            playbook:
            <codeblock>cd ~/scratch/ansible/next/hos/ansible
ansible-playbook -i hosts/verb_hosts monasca-agent-status.yml</codeblock></li>
        </ol>
      </sectiondiv>
    </section>
  </body>
</topic>
