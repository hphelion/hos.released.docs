<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="min_hardware">
  <title><ph conkeyref="HOS-conrefs/product-title"/>Hardware and Software Support Matrix</title>
  <body>
    <!--not tested-->
    <p conkeyref="HOS-conrefs/applies-to"/>
    <section id="about">
      <p>This document lists the details about the supported hardware and software for <keyword
          keyref="kw-hos-phrase"/></p>
      <ul>
        <li><xref href="hardware.dita#min_hardware/openstack">OpenStack Version
          Information</xref></li>
        <li><xref href="hardware.dita#min_hardware/supported_hardware">Supported
          Hardware</xref></li>
        <li><xref href="hardware.dita#min_hardware/supported_configs">Supported Hardware
            Configurations</xref></li>
        <li><xref href="hardware.dita#min_hardware/perf_notes">Notes about Performance</xref></li>
        <li><xref href="hardware.dita#min_hardware/disk_calc">Disk Calculator for Compute-Centric
            Deployments</xref></li>
        <li><xref href="hardware.dita#min_hardware/guestos-kvm">KVM Guest OS Support</xref></li>
        <li><xref href="hardware.dita#min_hardware/guestos-esx">ESX Guest OS Support</xref></li>
        <li><xref href="hardware.dita#min_hardware/guestos-ironic">Ironic Guest OS
          Support</xref></li>
      </ul>
    </section>
    <section id="openstack"><title>OpenStack Version Information</title>
      <p><keyword keyref="kw-hos-phrase"/> services have been updated to the <xref
          href="http://www.openstack.org/software/liberty" scope="external" format="html">OpenStack
          Liberty</xref> release. See <xref href="liberty_features.dita">OpenStack Liberty
          Features</xref> for more details.</p>
    </section>


    <section id="supported_hardware"><title>Supported Hardware</title>
      <p>For information about the supported hardware in <keyword keyref="kw-hos-phrase"/>, see
          <xref href="http://helionready.hpcloud.com/ihv/" format="html" scope="external">HPE Helion
          Ready Solution Catalog</xref>.</p>
    </section>


    <section id="supported_configs">
      <title>Supported Hardware Configurations</title>
      <p><keyword keyref="kw-hos-phrase"/> supports the following hardware configurations for a
        deployment.</p>
      <p><b>Storage Interconnects/Protocols</b></p>
      <ul>
        <li>10Gb Ethernet.</li>
        <li>Software iSCSi</li>
        <li>FibreChannel (FC)</li>
      </ul>
      <!--  TODO Check with Ollie about what is not supported for multipath -->
      <!-- https://jira.hpcloud.net/browse/DOCS-3054 -->
      <p id="multipath"><b>Multipath</b></p>
      <sectiondiv id="multipath_hardware">
        <p><keyword keyref="kw-hos-phrase"/> supports Fibre Channel and FCoE boot from SAN in
          multipath environments. The following list outlines the current limitations based on
          testing: </p>
        <ul>
          <li><b>Emulex based LPE1605 Native Fibre Channel</b> - Up to 1024 paths during boot</li>
          <li><b>Qlogic based SN100Q Native Fibre Channel</b> - Up to 1024 paths during boot </li>
          <li><b>Emulex Flex Fabric 650 series</b> - Up to 1024 paths during boot</li>
          <li><b>Emulex Flex Fabric 554FLB</b> - Up to 1024 paths during boot</li>
          <li><b>Qlogic Flex Fabric 536 and 630 series</b> - Not yet supported</li>

        </ul>
      </sectiondiv>
    </section>



    <section id="perf_notes"><title>Notes about Performance</title>
      <p>We have the following recommendations to ensure good performance of your cloud
        environment:</p>
      <ul>
        <li>On the control plane nodes, you will want good I/O performance. Your array controllers
          must have cache controllers and we advise against the use of RAID-5.</li>
        <li>On compute nodes, the I/O performance will influence the virtual machine start-up
          performance. We also recommend the use of cache controllers in your storage arrays.</li>
        <li>If you are using dedicated object storage (Swift) nodes, in particular the account,
          container, and object servers, we recommend that your storage arrays have cache
          controllers.</li>
      </ul>
    </section>

    <section id="disk_calc">
      <title>Disk Calculator for Compute-Centric Deployments</title>
      <p>This topic provides guidance on how to estimate the amount of disk space required for a
        compute-centric Helion OpenStack deployment. To accurately estimate the disk space needed,
        it is important to understand how Helion utilizes resources. Although there are a variety of
        factors, including the number of compute nodes, a large portion of the utilization is driven
        by operational tools, such as monitoring, metering, and logging.</p>
      <p>These instructions are intended for new installations. The process is slightly different
        for an upgrade where you are starting with an existing deployment. For information on how to
        estimate disk size for an upgrade, see the <xref href="upgrade/update_disk_models.dita"/>
        topic.</p>
      <note type="attention">The disk calculator does not accurately estimate a Swift-centric
        deployment at this time. For more information on Swift, see the <xref
          href="recommended_hardware_minimums.dita#rec_min/min_requirements_swift">Recommended
          minimum hardware requirements for an entry-scale Swift model</xref> topic.</note>
      <p>The usage of disk space by operational tools can be estimated from the following
        parameters: <ul>
          <li><b>Number of compute nodes</b> + <b>Number of VM's running on each compute
            node</b></li>
          <li><b>Number of services being monitored or metered</b> + <b>Amount of logs
            created</b></li>
          <li><b>Retention periods for operational data</b> (for Elastic Search, Vertica/InfluxDB,
            Kafka, and in the /var/log directory)</li>
        </ul></p>
      <note type="attention">If you also enable auditing, follow the steps in the <xref
          href="hardware.dita#min_hardware/disk_calc_audit_adj">Audit Logging Adjustment</xref>
        section to enter additional input parameters.</note>
      <p><b>Disk Estimation Process</b>
      </p>
      <p>Helion OpenStack provides entry scale and scale-out models for deployment. This disk
        estimation tool, currently in a spreadsheet form, helps you decide which disk model to start
        from as well as what customizations you need to meet your deployment requirements. The disk
        estimation process also provides default settings and minimum values for the parameters that
        drive disk size. <note type="attention">Kafka is the queuing system used to process metering
          monitoring and logging (MML) data. Kakfa stores the queued data on disk, so the disk space
          available will have a large impact on the amount of data the MML systems can process.
          Providing less than the minimum disk space for Kakfa will result in loss of MML data and
          can affect other components on the control plane. The default for Kafka is 1 hour which is
          17 GB.</note></p>
      <p><b>To estimate the disk sizes required for your deployment:</b></p>
      <ol>
        <li><xref href="hardware.dita#min_hardware/disk_calc_input">Enter input
          parameters.</xref></li>
        <li>If you also enable auditing, follow the steps in the <xref
            href="hardware.dita#min_hardware/disk_calc_audit_adj">Audit Logging Adjustment</xref>
          section to enter additional input parameters.</li>
        <li><xref href="hardware.dita#min_hardware/disk_calc_select">Select the deployment model you
            want to support based on the calculations.</xref></li>
        <li><xref href="hardware.dita#min_hardware/disk_calc_match">Match the selected deployment to
            a disk model example.</xref></li>
      </ol>
    </section>

    <section id="disk_calc_input">
      <title>Enter Input Parameters</title> The Disk Calculator spreadsheet automatically displays
      the minimum requirements for the components that define disk size. You can replace the default
      values with either the number you have to work with or the number that you want to support.
        <note type="attention">If you want to enable audit logging, follow the steps in the <xref
          href="hardware.dita#min_hardware/disk_calc_audit_adj">Audit Logging Adjustment</xref>
        section to enter additional input parameters.</note><table id="table_disk_calc_input">
        <tgroup cols="3">
          <colspec colname="c1" colnum="1"/>
          <colspec colname="c2" colnum="2"/>
          <colspec colname="c3" colnum="3"/>
          <thead>
            <row>
              <entry>Input Parameter</entry>
              <entry>Default</entry>
              <entry>Minimum</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>System Memory</entry>
              <entry>64 GB</entry>
              <entry>64 GB</entry>
            </row>
            <row>
              <entry>Compute Nodes</entry>
              <entry>100</entry>
              <entry>100</entry>
            </row>
            <row>
              <entry>VMs per Compute Node</entry>
              <entry>40</entry>
              <entry>40</entry>
            </row>
            <row>
              <entry>Component: Vertica</entry>
              <entry>45 days retention period</entry>
              <entry>30 days</entry>
            </row>
            <row>
              <entry>Component: Logging</entry>
              <entry>22 services covered <p>7 days retention period</p></entry>
              <entry><p> </p>7 days retention period</entry>
            </row>
            <row>
              <entry>Component: Kafka (message queue)</entry>
              <entry>0.17 of an hour retention period</entry>
              <entry>0.042 of an hour retention period</entry>
            </row>
            <row>
              <entry>Component: Elastic Search (log storage)</entry>
              <entry>7 days retention period</entry>
              <entry>7 days retention period</entry>
            </row>
            <row>
              <entry>Component: Audit</entry>
              <entry>0 days retention period</entry>
              <entry>0 days retention period</entry>
            </row>
          </tbody>
        </tgroup>
      </table> The following diagram shows the input parameters in the spreadsheet. <p>
        <image href="../media/DiskCalc1.png" placement="break"/>
      </p>
      <p>To provide the paramters required to estimate disk size:</p><ol>
        <li><xref href="https://docs.hpcloud.com/3.x/media/hos.docs/diskcalc.xlsx"
            format="html" scope="external">Open the disk calculator spreadsheet</xref>.</li>
        <li>At the bottom of the spreadsheet, click on the <b>Draft Sizing Tool4</b> tab.</li>
        <li> To set the server RAM size, replace the default value in the <b>System Memory</b>
          field.</li> 
        <li>To set the number of compute nodes, replace the default in the <b>Compute Nodes</b>
          field.</li>
        <li>To set the average number of virtual machines per compute node, replace the default in
          the <b>VM's per Compute Node</b> field.</li>
        <li>To set the number of days you want the metering and logging files retained, replace the
          default in the <b>Vertica Retention Period</b> field.</li>
        <li>To set logging values, replace the default in <b>Number of Services Covered</b> and
            <b>Retention Period</b>. <note type="attention">If you enable additional logging of
            services than those set by default, then you must increase the number in the <b>Logging
              Number of Services</b> Field.</note></li>
        <li>To set a value for Kafka messages to be retained, replace the default in the <b>Kafka
            Retention Period</b> field.</li>
        <li>To set a value for Elastic Search log file retention, replace the default in the
            <b>Elastic Search Retention Period</b> field.</li>
        <li>To set a value for Audit logging file retention, replace the default in the <b>Audit
            Retention Period</b> field.</li>
      </ol></section>

    <section id="disk_calc_audit_adj">
      <title>Audit Logging Adjustment</title>
      <p>If you want to enable audit logging, you must enter additional input parameters to ensure
        there is enough room to retain the audit logs. The following diagram shows the parameters
        you need to specify in the Disk Calculator spreadsheet.</p>
      <p><image href="../media/DiskCalc2.png" placement="break"/></p>
      <p>To add audit logging to disk size calculations:</p>
      <ol>
        <li>Determine which services you have enabled to collect audit logging information. This is
          part of HLM configuration.</li>
        <li>Total up the audit log space required by the hosting control plane cluster, including
          api/core, Neutron, Swift, MMLB and MySQL/RabbitMQ.</li>
        <li>Manually enter these values for each cluster in the /var/audit line in the spreadsheet.
            <note type="attention">If you enable logging for services beyond the defaults, you must
            change the <b>Number of Services on a Cluster</b> field in the spreadsheet. It is
            recommended that you increase the total services covered as well as increment the number
            on the appropriate cluster. For example, if you enable Apache logs on the core services,
            then the total would increase to 23 and the api/core services entry would change from 13
            to 14.</note></li>
        <li>To include Glance image space in your estimation, determine the size of the images that
          will be cached.</li>
        <li>Enter the total size needed to store Glance images in the
            <b>/var/lib/glance/work_dir</b> field.</li>
      </ol>
    </section>

    <section id="disk_calc_select">
      <title>Select the Deployment Model</title> To decide which architecture will meet all of your
      requirements, use the values given in the Disk Calculator spreadsheet. Keeping in mind the
      rough scale you expect to target as well as any need to separate services, choose an Entry
      Scale, Entry Scale MML, or Mid Scale deployment. Once you have chosen a deployment you can
      match it to the sample disk models in the <xref
        href="hardware.dita#min_hardware/disk_calc_match">Match to a Disk Model</xref> section. The
      following diagram shows the deployment options that are recommended if you use the default
      values in the Disk Calculator spreadsheet. <p><image href="../media/DiskCalc3.png"
          placement="break" id="image_cmk_lxc_wv"/></p> For example, in the above diagram, if you
      wanted to choose an Entry Scale MML deployment, the calculator recommends the following disk
      sizes: <ul id="ul_uwg_fs2_wv">
        <li>216 GB for API/Core Service</li>
        <li>216 GB for Neutron (networking)</li>
        <li>216 GB for Swift (storage)</li>
        <li>573 GB for MMLB</li>
        <li>252 GB for MySQL/RabbitMQ</li>
      </ul>
    </section>

    <section id="disk_calc_match">
      <title>Match to a Disk Model</title>
      <p>For each of the entry-scale and scale-out cloud models, there is a set of associated disk
        models that can be used as the basis for your deployment. These models provide examples of
        pontetial parameters for operational tools and are expected to be used as the starting point
        for actual deployments. Since each deployment can vary greatly, the disk calculator
        spreadsheet provides a way to create the basic disk model and customize it to fit the
        specific parameters your deployment. Once you have estimated disk sizes and chosen a
        deployment architecture, you can choose which example disk partitioning file to use from the
        tables below. Keep in mind if you are enabling more options than are listed in the Disk
        Calculator, or if you want to plan for growth, you will need to manually adjust paramters as
        necessary.</p>
      <p>Disk models are provided for each deployment option based on the expected size of the disk
        available to the control plane nodes. The available space is then partitioned by percentage
        to be allocated to each of the required volumes on the control plane. Each of the disk
        models is targeted at a specific set of parameters which can be found in the following
        tables: <ul>
          <li><xref href="hardware.dita#min_hardware/disk_calc_entry">Entry Scale:</xref> 600 GB, 1
            TB</li>
          <li><xref href="hardware.dita#min_hardware/disk_calc_Mid">Mid Scale/ Entry Scale MML
              Servers:</xref> 600 GB, 2 TB, 4.5 TB</li>
        </ul>
      </p>
    </section>

    <section id="disk_calc_entry">
      <title>Entry Scale Disk Models</title>
      <p>These models include a single cluster of control plane nodes and all services.</p>
      <p><b>600 GB Entry Scale</b>
        <table id="table_disk_matchE6">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1" colwidth="163.5pt"/>
            <colspec colname="c2" colnum="2" colwidth="277.5pt"/>
            <thead>
              <row>
                <entry>Component</entry>
                <entry>Parameters</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>compute nodes</entry>
                <entry>100. This model provides lower than recommended retention and should only be
                  used for POC deployments.</entry>
              </row>
            </tbody>
          </tgroup>
        </table></p>
      <p><b>1 TB Entry Scale</b>
        <table id="table_disk_matchE1">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1" colwidth="156.75pt"/>
            <colspec colname="c2" colnum="2" colwidth="132pt"/>
            <thead>
              <row>
                <entry>Component</entry>
                <entry>Parameters</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>compute nodes</entry>
                <entry>100</entry>
              </row>
              <row>
                <entry>local logging<p>var/log</p></entry>
                <entry>7 day retention</entry>
              </row>
              <row>
                <entry>metering/monitoring<p>/var/vertica</p></entry>
                <entry>45 day retention</entry>
              </row>
              <row>
                <entry>centralized logging<p>/var/lib/elasticsearch</p></entry>
                <entry>7 day retention</entry>
              </row>
              <row>
                <entry>Kafka Message Queue<p>/var/kafka</p></entry>
                <entry>4 hour retention</entry>
              </row>
            </tbody>
          </tgroup>
        </table></p>
    </section>

    <section id="disk_calc_Mid">
      <title>MML Disk Models</title>
      <p>These mid-scale and entry-scale MML models include seperate control plane nodes for core
        services, metering/monitoring/logging, and MySQL/RabbitMQ. Optionally you can also seperate
        out Swift (storage) and Neutron (networking). MML servers are the ones that will need
        modification based on the scale and operational parameters.</p>
      <p><b>600 GB MML Server</b>
        <table id="table_disk_matchM6">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1" colwidth="163.5pt"/>
            <colspec colname="c2" colnum="2" colwidth="277.5pt"/>
            <thead>
              <row>
                <entry>Component</entry>
                <entry>Parameters</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>compute nodes</entry>
                <entry>100</entry>
              </row>
              <row>
                <entry>local logging<p>var/log</p></entry>
                <entry>7 day retention</entry>
              </row>
              <row>
                <entry>metering/monitoring<p>/var/vertica</p></entry>
                <entry>30 day retention<p>
                    <note type="caution">45 days is the default minimum.</note>
                  </p></entry>
              </row>
              <row>
                <entry>centralized logging<p>/var/lib/elasticsearch</p></entry>
                <entry>7 day retention</entry>
              </row>
              <row>
                <entry>Kafka Message Queue<p>/var/kafka</p></entry>
                <entry>4 hour retention</entry>
              </row>
            </tbody>
          </tgroup>
        </table></p>
      <p><b>2 TB MML Server</b>
        <table id="table_disk_matchM2T">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1" colwidth="156.75pt"/>
            <colspec colname="c2" colnum="2" colwidth="132pt"/>
            <thead>
              <row>
                <entry>Component</entry>
                <entry>Parameters</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>compute nodes</entry>
                <entry>300</entry>
              </row>
              <row>
                <entry>local logging<p>var/log</p></entry>
                <entry>7 day retention</entry>
              </row>
              <row>
                <entry>metering/monitoring<p>/var/vertica</p></entry>
                <entry>45 day retention</entry>
              </row>
              <row>
                <entry>centralized logging<p>/var/lib/elasticsearch</p></entry>
                <entry>7 day retention</entry>
              </row>
              <row>
                <entry>Kafka Message Queue<p>/var/kafka</p></entry>
                <entry>12 hour retention</entry>
              </row>
            </tbody>
          </tgroup>
        </table></p>
      <p><b>4.5 TB MML Server</b>
        <table id="table_disk_matchM4T">
          <tgroup cols="2">
            <colspec colname="c1" colnum="1" colwidth="156.75pt"/>
            <colspec colname="c2" colnum="2" colwidth="132pt"/>
            <thead>
              <row>
                <entry>Component</entry>
                <entry>Parameters</entry>
              </row>
            </thead>
            <tbody>
              <row>
                <entry>compute nodes</entry>
                <entry>300</entry>
              </row>
              <row>
                <entry>local logging<p>var/log</p></entry>
                <entry>7 day retention</entry>
              </row>
              <row>
                <entry>metering/monitoring<p>/var/vertica</p></entry>
                <entry>45 day retention</entry>
              </row>
              <row>
                <entry>centralized logging<p>/var/lib/elasticsearch</p></entry>
                <entry>45 day retention</entry>
              </row>
              <row>
                <entry>Kafka Message Queue<p>/var/kafka</p></entry>
                <entry>12 hour retention</entry>
              </row>
            </tbody>
          </tgroup>
        </table></p>
    </section>

    <lines>
  
</lines>









    <section id="guestos-kvm">
      <title>KVM Guest OS Support</title>
      <p>A <b>Verified</b> Guest OS has been tested by HPE and appears to function properly as a
        Nova compute virtual machine on <keyword keyref="kw-hos-phrase"/>.</p>
      <p>A <b>Certified</b> Guest OS has been officially tested by the operating system vendor, or
        by HPE under the vendor's authorized program, and will be supported by the operating system
        vendor as a Nova compute virtual machine on <keyword keyref="kw-hos-phrase"/>.</p>
      <table frame="all" rowsep="1" colsep="1" id="table_xbd_sbq_yt">
        <tgroup cols="3">
          <colspec colname="c1" colnum="1"/>
          <colspec colname="c2" colnum="2"/>
          <colspec colname="c3" colnum="3"/>
          <thead>
            <row>
              <entry>KVM Guest Operating System</entry>
              <entry>Verified</entry>
              <entry>Certified</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>Windows Server 2008</entry>
              <entry/>
              <entry>Yes</entry>
            </row>
            <row>
              <entry>Windows Server 2008 R2</entry>
              <entry/>
              <entry>Yes</entry>
            </row>
            <row>
              <entry>Windows Server 2012</entry>
              <entry/>
              <entry>Yes</entry>
            </row>
            <row>
              <entry>Windows Server 2012 R2</entry>
              <entry/>
              <entry>Yes</entry>
            </row>
            <row>
              <entry>CentOS 6.7</entry>
              <entry>Yes</entry>
              <entry/>
            </row>
            <row>
              <entry>CentOS 7.1</entry>
              <entry>Yes</entry>
              <entry/>
            </row>
            <row>
              <entry>CoreOS - Stable</entry>
              <entry>Yes</entry>
              <entry/>
            </row>
            <row>
              <entry>Debian 7.9</entry>
              <entry>Yes</entry>
              <entry/>
            </row>
            <row>
              <entry>Debian 8.2</entry>
              <entry>Yes</entry>
              <entry/>
            </row>
            <row>
              <entry>RHEL 6.7</entry>
              <entry>Yes</entry>
              <entry/>
            </row>
            <row>
              <entry>RHEL 7.1</entry>
              <entry>Yes</entry>
              <entry/>
            </row>
            <row>
              <entry>RHEL Atomic</entry>
              <entry>Yes</entry>
              <entry/>
            </row>
            <row>
              <entry>SLES 11 SP4</entry>
              <entry>Yes</entry>
              <entry/>
            </row>
            <row>
              <entry>SLES 12</entry>
              <entry>Yes</entry>
              <entry/>
            </row>
            <row>
              <entry>Ubuntu 14.04</entry>
              <entry>Yes</entry>
              <entry/>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>


    <section id="guestos-esx">
      <title>ESX Guest OS Support</title>
      <p>For ESX, refer to the <xref
          href="http://www.vmware.com/resources/compatibility/search.php?action=search&amp;deviceCategory=software&amp;advancedORbasic=advanced&amp;maxDisplayRows=50&amp;key=&amp;productId=4&amp;gos_vmw_product_release%5B%5D=90&amp;datePosted=-1&amp;partnerId%5B%5D=-1&amp;os_bits=-1&amp;os_use%5B%5D=-1&amp;os_family%5B%5D=-1&amp;os_type%5B%5D=-1&amp;rorre=0"
          scope="external" format="html">VMware Compatibility Guide</xref>.</p>
    </section>


    <section id="guestos-ironic">
      <title>Ironic Guest OS Support</title>
      <p>A <b>Verified</b> Guest OS has been tested by HPE and appears to function properly as a
        bare metal instance on <keyword keyref="kw-hos-phrase"/>.</p>
      <p>A <b>Certified</b> Guest OS has been officially tested by the operating system vendor, or
        by HPE under the vendor's authorized program, and will be supported by the operating system
        vendor as a bare metal instance on <keyword keyref="kw-hos-phrase"/>.</p>
      <table frame="all" rowsep="1" colsep="1" id="table-guestos-ironic">
        <tgroup cols="3">
          <colspec colname="c1" colnum="1"/>
          <colspec colname="c2" colnum="2"/>
          <colspec colname="c3" colnum="3"/>
          <thead>
            <row>
              <entry>Ironic Guest Operating System</entry>
              <entry>Verified</entry>
              <entry>Certified</entry>
            </row>
          </thead>
          <tbody>
            <row>
              <entry>RHEL 6.7</entry>
              <entry>Yes</entry>
              <entry/>
            </row>
            <row>
              <entry>RHEL 7.1</entry>
              <entry>Yes</entry>
              <entry/>
            </row>

            <!-- IRONIC-360 -->
            <!--            <row>
              <entry>SLES 11 SP4</entry>
              <entry>Yes</entry>
              <entry/>
            </row>
            <row>
              <entry>SLES 12</entry>
              <entry>Yes</entry>
              <entry/>
            </row>-->
            <row>
              <entry>Ubuntu 14.04</entry>
              <entry>Yes</entry>
              <entry/>
            </row>
          </tbody>
        </tgroup>
      </table>
    </section>






  </body>
</topic>
